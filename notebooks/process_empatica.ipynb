{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading AVRO files and non-wear detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "~ 2 min for reading and concatenating into a list for 7 days of data\n",
    "\n",
    "**With Pandas**\n",
    "\n",
    "- ~ 2.30 min for transforming it into a pd.DataFrame\n",
    "- ~ 1.30 min for saving to accelerometer to csv\n",
    "- ~ 3 sec for saving ppg, acc, and temp to parquet\n",
    "\n",
    "**With Polars**\n",
    "\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io.embraceplus.read_avro_mod import ReadEmpaticaAvro\n",
    "empatica_reader = ReadEmpaticaAvro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing day 1/8\n"
     ]
    }
   ],
   "source": [
    "#### Change the paths below to the location of the data on your machine ####\n",
    "data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/participant_data/\"\n",
    "\n",
    "#### Change the subject ID and device ID below to the subject and device you want to process ####\n",
    "sub_ID = \"00007\"\n",
    "device_ID = \"3YK3J151VJ\"\n",
    "\n",
    "days = sorted(os.listdir(data_path))\n",
    "days = [day for day in days if day[0] != \".\"] # remove hidden files (needed for MacOS users)\n",
    "\n",
    "acc = []\n",
    "ppg = []\n",
    "temp = []\n",
    "time = []\n",
    "time_temp = []\n",
    "tags = []\n",
    "\n",
    "for i, day in enumerate(days):\n",
    "    \n",
    "    print(f\"Processing day {i+1}/{len(days)}\")\n",
    "\n",
    "    folder_day = data_path + day + \"/\" + sub_ID + \"-\" + device_ID + \"/raw_data/v6\"\n",
    "\n",
    "    avro_files = sorted(glob.glob(folder_day + \"/*.avro\"))\n",
    "\n",
    "    for avro_file in avro_files:\n",
    "        \n",
    "        data = empatica_reader.read(file=avro_file)\n",
    "\n",
    "        acc.extend(data[\"acc\"])\n",
    "\n",
    "        ppg.extend(data[\"bvp\"])\n",
    "\n",
    "        time.extend(data[\"time\"]) # Same for acc and ppg\n",
    "\n",
    "        temp.extend(data[\"temp\"])\n",
    "        time_temp.extend(data[\"time_temp\"])\n",
    "\n",
    "        tags.extend(data[\"tags\"])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1716210262.022092, 1716253853.037992]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame(acc, columns=[\"x\", \"y\", \"z\"], index = pd.to_datetime(time, unit=\"s\")).sort_index()\n",
    "ppg_df = pd.DataFrame(ppg, columns=[\"ppg\"], index = pd.to_datetime(time, unit=\"s\")).sort_index()\n",
    "temp_df = pd.DataFrame(temp, columns=[\"temp\"], index = pd.to_datetime(time_temp, unit=\"s\")).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect non-wear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to divide it into portions when the device was in charge\n",
    "\n",
    "t_charge_end = acc_df.index[acc_df.index.to_series().diff().dt.total_seconds() > 60*10] # if the difference between two consecutive timestamps is more than 10 minutes (**), it means the device was in charge\n",
    "t_charge_start = acc_df.index[np.where(acc_df.index.to_series().diff().dt.total_seconds() > 60*10)[0]-1] # the start of the charge is the timestamp before the end of the charge\n",
    "t_charge = pd.DataFrame({\"start\": t_charge_start, \"end\": t_charge_end})\n",
    "\n",
    "good_portions = pd.DataFrame(columns=[\"start\", \"end\"]) # I will store the portions when the device was not in charge here\n",
    "good_portions[\"start\"] = t_charge[\"end\"].iloc[:-1].reset_index(drop=True)\n",
    "good_portions[\"end\"] = t_charge[\"start\"].iloc[1:].reset_index(drop=True)\n",
    "start_first_charge = t_charge[\"start\"].iloc[0]\n",
    "end_last_charge = t_charge[\"end\"].iloc[-1]\n",
    "\n",
    "# Segment the data into portions when the device was not in charge and perform nonwear detection\n",
    "# Add the first portion\n",
    "acc_df_portions = [acc_df[:start_first_charge]]\n",
    "ppg_df_portions = [ppg_df[:start_first_charge]]\n",
    "temp_df_portions = [temp_df[:start_first_charge]]\n",
    "\n",
    "for i, row in good_portions.iterrows():\n",
    "\n",
    "    if row[\"end\"] - row[\"start\"] < pd.Timedelta(\"10 min\"): # if the portion is less than 10 minutes (**), skip it\n",
    "        continue\n",
    "\n",
    "    acc_df_portions.append(acc_df[row[\"start\"]:row[\"end\"]])\n",
    "    ppg_df_portions.append(ppg_df[row[\"start\"]:row[\"end\"]])\n",
    "    temp_df_portions.append(temp_df[row[\"start\"]:row[\"end\"]])\n",
    "\n",
    "# Add the last portion\n",
    "acc_df_portions.append(acc_df[end_last_charge:])\n",
    "ppg_df_portions.append(ppg_df[end_last_charge:])\n",
    "temp_df_portions.append(temp_df[end_last_charge:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonwear.DETACH import nimbaldetach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/dvs9gy2x1fq3xdz6r9lt_t_40000gp/T/ipykernel_57254/237738474.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  acc.loc[datetime_start_nw:datetime_end_nw] = np.nan\n",
      "/var/folders/8x/dvs9gy2x1fq3xdz6r9lt_t_40000gp/T/ipykernel_57254/237738474.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp.loc[datetime_start_nw:datetime_end_nw] = np.nan\n",
      "/var/folders/8x/dvs9gy2x1fq3xdz6r9lt_t_40000gp/T/ipykernel_57254/237738474.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ppg.loc[datetime_start_nw:datetime_end_nw] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# for each of them, perform NW detection\n",
    "acc_df_cleaned = []\n",
    "temp_df_cleaned = []\n",
    "ppg_df_cleaned = []\n",
    "for i, (acc, temp, ppg) in enumerate(zip(acc_df_portions, temp_df_portions, ppg_df_portions)):\n",
    "\n",
    "    start_stop_nw, _ = nimbaldetach(acc['x'].values, acc['y'].values, acc['z'].values, temp[\"temp\"].values, accel_freq=64, temperature_freq=1, quiet=True)\n",
    "\n",
    "    # Remove non-wear periods\n",
    "    for i, row in start_stop_nw.iterrows():\n",
    "        datetime_start_nw = acc.index[row[\"Start Datapoint\"]]\n",
    "        datetime_end_nw = acc.index[row[\"End Datapoint\"]]\n",
    "        acc.loc[datetime_start_nw:datetime_end_nw] = np.nan\n",
    "        temp.loc[datetime_start_nw:datetime_end_nw] = np.nan\n",
    "        ppg.loc[datetime_start_nw:datetime_end_nw] = np.nan\n",
    "    acc_portion = acc.dropna()\n",
    "    temp_portion = temp.dropna()\n",
    "    ppg_portion = ppg.dropna()\n",
    "\n",
    "    acc_df_cleaned.append(acc_portion)\n",
    "    temp_df_cleaned.append(temp_portion)\n",
    "    ppg_df_cleaned.append(ppg_portion)\n",
    "\n",
    "acc_df_cleaned = pd.concat(acc_df_cleaned)\n",
    "temp_df_cleaned = pd.concat(temp_df_cleaned)\n",
    "ppg_df_cleaned = pd.concat(ppg_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((553410, 1), (35417280, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.shape, acc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input\"\n",
    "acc_df_parquet = pd.read_parquet(save_data_path + \"/acc.parquet\") * 1000\n",
    "input_GGIR_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input_new\"\n",
    "\n",
    "acc_df_GGIR = acc_df_parquet.copy()\n",
    "t_gaps_start = acc_df_GGIR.index[acc_df_GGIR.index.to_series().diff().dt.total_seconds() > 60*1] # if the difference between two consecutive timestamps is more than 1 minute, it means there is a gap\n",
    "t_gaps_end = acc_df_GGIR.index[np.where(acc_df_GGIR.index.to_series().diff().dt.total_seconds() > 60*1)[0]-1] # the start of the gap is the timestamp before the end of the gap\n",
    "t_gaps = pd.DataFrame({\"start\": t_gaps_end, \"end\": t_gaps_start})\n",
    "for i, row in t_gaps.iterrows():\n",
    "    acc_df_GGIR = acc_df_GGIR.loc[acc_df_GGIR.index < row[\"start\"]]\n",
    "    acc_df_GGIR = pd.concat([acc_df_GGIR, pd.DataFrame(index=pd.date_range(start=row[\"start\"], end=row[\"end\"], freq=f\"{1/64} s\"))])\n",
    "    acc_df_GGIR = pd.concat([acc_df_GGIR, acc_df_GGIR.loc[acc_df_GGIR.index > row[\"end\"]]])\n",
    "acc_df_GGIR.to_csv(input_GGIR_path + \"/acc_GGIR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input\"\n",
    "input_GGIR_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input_new\"\n",
    "\n",
    "# Save to csv for GGIR - I need to fill gaps with NaNs\n",
    "acc_df_GGIR = acc_df.copy() * 1000 # convert to mg\n",
    "t_gaps_start = acc_df_GGIR.index[acc_df_GGIR.index.to_series().diff().dt.total_seconds() > 60*1] # if the difference between two consecutive timestamps is more than 1 minute, it means there is a gap\n",
    "t_gaps_end = acc_df_GGIR.index[np.where(acc_df_GGIR.index.to_series().diff().dt.total_seconds() > 60*1)[0]-1] # the start of the gap is the timestamp before the end of the gap\n",
    "t_gaps = pd.DataFrame({\"start\": t_gaps_end, \"end\": t_gaps_start})\n",
    "for i, row in t_gaps.iterrows():\n",
    "    acc_df_GGIR = acc_df_GGIR.loc[acc_df_GGIR.index < row[\"start\"]]\n",
    "    acc_df_GGIR = pd.concat([acc_df_GGIR, pd.DataFrame(index=pd.date_range(start=row[\"start\"], end=row[\"end\"], freq=f\"{1/64} s\"))])\n",
    "    acc_df_GGIR = pd.concat([acc_df_GGIR, acc_df_GGIR.loc[acc_df_GGIR.index > row[\"end\"]]])\n",
    "acc_df_GGIR.to_csv(input_GGIR_path + \"/acc_GGIR.csv\")\n",
    "\n",
    "# Save to parquet for further analysis\n",
    "# acc_df_cleaned.to_parquet(save_data_path + \"/acc.parquet\")\n",
    "# temp_df_cleaned.to_parquet(save_data_path + \"/temp.parquet\")\n",
    "# ppg_df_cleaned.to_parquet(save_data_path + \"/ppg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7a0bfeb1-e3c8-4884-ae21-67735023d8d1",
       "rows": [
        [
         "0",
         "2024-05-20 13:02:55.531980990",
         "-68.359375",
         "408.69140625",
         "931.15234375"
        ],
        [
         "1",
         "2024-05-20 13:02:55.547605991",
         "-68.359375",
         "403.3203125",
         "930.17578125"
        ],
        [
         "2",
         "2024-05-20 13:02:55.563230991",
         "-71.2890625",
         "397.94921875",
         "919.43359375"
        ],
        [
         "3",
         "2024-05-20 13:02:55.578855991",
         "-69.82421875",
         "400.87890625",
         "925.78125"
        ],
        [
         "4",
         "2024-05-20 13:02:55.594480991",
         "-64.453125",
         "409.66796875",
         "923.33984375"
        ],
        [
         "5",
         "2024-05-20 13:02:55.610105991",
         "-77.1484375",
         "400.390625",
         "930.17578125"
        ],
        [
         "6",
         "2024-05-20 13:02:55.625730991",
         "-70.80078125",
         "389.16015625",
         "928.22265625"
        ],
        [
         "7",
         "2024-05-20 13:02:55.641355991",
         "-72.75390625",
         "393.06640625",
         "923.828125"
        ],
        [
         "8",
         "2024-05-20 13:02:55.656980991",
         "-81.0546875",
         "396.484375",
         "929.6875"
        ],
        [
         "9",
         "2024-05-20 13:02:55.672605991",
         "-64.453125",
         "401.3671875",
         "924.8046875"
        ],
        [
         "10",
         "2024-05-20 13:02:55.688230991",
         "-62.98828125",
         "398.92578125",
         "926.26953125"
        ],
        [
         "11",
         "2024-05-20 13:02:55.703855991",
         "-71.77734375",
         "397.4609375",
         "925.78125"
        ],
        [
         "12",
         "2024-05-20 13:02:55.719480991",
         "-68.359375",
         "394.04296875",
         "925.78125"
        ],
        [
         "13",
         "2024-05-20 13:02:55.735105991",
         "-66.40625",
         "397.4609375",
         "925.29296875"
        ],
        [
         "14",
         "2024-05-20 13:02:55.750730991",
         "-70.80078125",
         "396.97265625",
         "923.33984375"
        ],
        [
         "15",
         "2024-05-20 13:02:55.766355991",
         "-75.1953125",
         "395.01953125",
         "922.36328125"
        ],
        [
         "16",
         "2024-05-20 13:02:55.781980991",
         "-76.66015625",
         "393.06640625",
         "927.734375"
        ],
        [
         "17",
         "2024-05-20 13:02:55.797605991",
         "-72.265625",
         "396.97265625",
         "926.26953125"
        ],
        [
         "18",
         "2024-05-20 13:02:55.813230991",
         "-68.359375",
         "399.90234375",
         "923.33984375"
        ],
        [
         "19",
         "2024-05-20 13:02:55.828855991",
         "-75.1953125",
         "396.484375",
         "923.828125"
        ],
        [
         "20",
         "2024-05-20 13:02:55.844480991",
         "-75.68359375",
         "392.08984375",
         "921.875"
        ],
        [
         "21",
         "2024-05-20 13:02:55.860105991",
         "-77.1484375",
         "406.73828125",
         "926.7578125"
        ],
        [
         "22",
         "2024-05-20 13:02:55.875730991",
         "-71.2890625",
         "395.99609375",
         "927.734375"
        ],
        [
         "23",
         "2024-05-20 13:02:55.891355991",
         "-67.3828125",
         "399.4140625",
         "933.59375"
        ],
        [
         "24",
         "2024-05-20 13:02:55.906980991",
         "-68.359375",
         "397.94921875",
         "931.640625"
        ],
        [
         "25",
         "2024-05-20 13:02:55.922605991",
         "-70.80078125",
         "393.5546875",
         "925.78125"
        ],
        [
         "26",
         "2024-05-20 13:02:55.938230991",
         "-67.3828125",
         "393.06640625",
         "922.8515625"
        ],
        [
         "27",
         "2024-05-20 13:02:55.953855991",
         "-69.82421875",
         "396.97265625",
         "927.734375"
        ],
        [
         "28",
         "2024-05-20 13:02:55.969480991",
         "-74.70703125",
         "394.04296875",
         "930.17578125"
        ],
        [
         "29",
         "2024-05-20 13:02:55.985105991",
         "-75.68359375",
         "395.5078125",
         "922.8515625"
        ],
        [
         "30",
         "2024-05-20 13:02:56.000730991",
         "-69.82421875",
         "387.6953125",
         "920.41015625"
        ],
        [
         "31",
         "2024-05-20 13:02:56.016355991",
         "-66.40625",
         "393.5546875",
         "922.8515625"
        ],
        [
         "32",
         "2024-05-20 13:02:56.031980991",
         "-69.82421875",
         "397.94921875",
         "922.8515625"
        ],
        [
         "33",
         "2024-05-20 13:02:56.047605991",
         "-72.265625",
         "395.99609375",
         "931.15234375"
        ],
        [
         "34",
         "2024-05-20 13:02:56.063230991",
         "-70.3125",
         "391.11328125",
         "927.734375"
        ],
        [
         "35",
         "2024-05-20 13:02:56.078855991",
         "-80.078125",
         "397.94921875",
         "930.6640625"
        ],
        [
         "36",
         "2024-05-20 13:02:56.094480991",
         "-68.84765625",
         "397.94921875",
         "924.31640625"
        ],
        [
         "37",
         "2024-05-20 13:02:56.110105991",
         "-79.1015625",
         "385.7421875",
         "925.29296875"
        ],
        [
         "38",
         "2024-05-20 13:02:56.125730990",
         "-76.66015625",
         "391.11328125",
         "922.8515625"
        ],
        [
         "39",
         "2024-05-20 13:02:56.141355991",
         "-71.77734375",
         "390.625",
         "920.41015625"
        ],
        [
         "40",
         "2024-05-20 13:02:56.156980991",
         "-75.68359375",
         "399.90234375",
         "927.24609375"
        ],
        [
         "41",
         "2024-05-20 13:02:56.172605991",
         "-67.87109375",
         "396.97265625",
         "929.19921875"
        ],
        [
         "42",
         "2024-05-20 13:02:56.188230991",
         "-82.03125",
         "390.13671875",
         "931.15234375"
        ],
        [
         "43",
         "2024-05-20 13:02:56.203855991",
         "-67.87109375",
         "400.390625",
         "926.7578125"
        ],
        [
         "44",
         "2024-05-20 13:02:56.219480991",
         "-67.3828125",
         "394.53125",
         "934.5703125"
        ],
        [
         "45",
         "2024-05-20 13:02:56.235105991",
         "-67.87109375",
         "396.97265625",
         "931.15234375"
        ],
        [
         "46",
         "2024-05-20 13:02:56.250730991",
         "-68.359375",
         "395.01953125",
         "925.78125"
        ],
        [
         "47",
         "2024-05-20 13:02:56.266355991",
         "-71.2890625",
         "394.04296875",
         "932.12890625"
        ],
        [
         "48",
         "2024-05-20 13:02:56.281980991",
         "-69.82421875",
         "398.4375",
         "928.7109375"
        ],
        [
         "49",
         "2024-05-20 13:02:56.297605991",
         "-75.1953125",
         "393.5546875",
         "928.7109375"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 38267338
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-20 13:02:55.531980990</td>\n",
       "      <td>-68.359375</td>\n",
       "      <td>408.691406</td>\n",
       "      <td>931.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-20 13:02:55.547605991</td>\n",
       "      <td>-68.359375</td>\n",
       "      <td>403.320312</td>\n",
       "      <td>930.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-20 13:02:55.563230991</td>\n",
       "      <td>-71.289062</td>\n",
       "      <td>397.949219</td>\n",
       "      <td>919.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-20 13:02:55.578855991</td>\n",
       "      <td>-69.824219</td>\n",
       "      <td>400.878906</td>\n",
       "      <td>925.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-20 13:02:55.594480991</td>\n",
       "      <td>-64.453125</td>\n",
       "      <td>409.667969</td>\n",
       "      <td>923.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267333</th>\n",
       "      <td>2024-05-27 11:08:55.250720977</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>-0.012207</td>\n",
       "      <td>1.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267334</th>\n",
       "      <td>2024-05-27 11:08:55.266345977</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.011719</td>\n",
       "      <td>1.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267335</th>\n",
       "      <td>2024-05-27 11:08:55.281970978</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>1.009277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267336</th>\n",
       "      <td>2024-05-27 11:08:55.297595978</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>-0.010254</td>\n",
       "      <td>1.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38267337</th>\n",
       "      <td>2024-05-27 11:08:55.313220978</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>1.014648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38267338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Unnamed: 0          x           y           z\n",
       "0         2024-05-20 13:02:55.531980990 -68.359375  408.691406  931.152344\n",
       "1         2024-05-20 13:02:55.547605991 -68.359375  403.320312  930.175781\n",
       "2         2024-05-20 13:02:55.563230991 -71.289062  397.949219  919.433594\n",
       "3         2024-05-20 13:02:55.578855991 -69.824219  400.878906  925.781250\n",
       "4         2024-05-20 13:02:55.594480991 -64.453125  409.667969  923.339844\n",
       "...                                 ...        ...         ...         ...\n",
       "38267333  2024-05-27 11:08:55.250720977   0.006348   -0.012207    1.010254\n",
       "38267334  2024-05-27 11:08:55.266345977   0.009277   -0.011719    1.010254\n",
       "38267335  2024-05-27 11:08:55.281970978   0.016602   -0.010254    1.009277\n",
       "38267336  2024-05-27 11:08:55.297595978   0.011719   -0.010254    1.010254\n",
       "38267337  2024-05-27 11:08:55.313220978   0.009277   -0.001953    1.014648\n",
       "\n",
       "[38267338 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_GGIR_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input_new\"\n",
    "acc_df_GGIR = pd.read_csv(input_GGIR_path + \"/acc_GGIR.csv\")\n",
    "acc_df_GGIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14c83e510>,\n",
       " <matplotlib.lines.Line2D at 0x17c8a5f40>,\n",
       " <matplotlib.lines.Line2D at 0x17c8a6120>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(acc_df_GGIR[[\"x\", \"y\", \"z\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input_new\"\n",
    "acc_df = pd.read_csv(save_data_path + \"/acc_new.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.check_accelerometer_temp import plot_acc_temp\n",
    "\n",
    "# Decide whether to plot in notebook or in a separate window\n",
    "from bokeh.plotting import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "processed_data_path = save_data_path\n",
    "plot_acc_temp(processed_data_path, accSMV = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GGIR output - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m output_GGIR_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_output_new/output_GGIR_input_new/results/QC/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m output_GGIR \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(output_GGIR_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart4_nightsummary_sleep_full.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m SPT \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, day_row \u001b[38;5;129;01min\u001b[39;00m output_GGIR\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Stupid thing to get the correct datetime for segmenting signals into day and night (but no alternatives I guess)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "output_GGIR_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_output_new/output_GGIR_input_new/results/QC/\"\n",
    "\n",
    "output_GGIR = pd.read_csv(output_GGIR_path + \"part4_nightsummary_sleep_full.csv\")\n",
    "\n",
    "SPT = []\n",
    "\n",
    "for i, day_row in output_GGIR.iterrows():\n",
    "    # Stupid thing to get the correct datetime for segmenting signals into day and night (but no alternatives I guess)\n",
    "    if output_GGIR[\"sleeponset_ts\"].iloc[0][0] == '0':\n",
    "        sleep_onset = pd.to_datetime(str(pd.to_datetime(day_row[\"calendar_date\"]).date() + pd.Timedelta(\"1d\")) + \" \" + day_row[\"sleeponset_ts\"])\n",
    "    else:\n",
    "        sleep_onset = pd.to_datetime(pd.to_datetime(day_row[\"calendar_date\"]).date() + \" \" + day_row[\"sleeponset_ts\"])\n",
    "\n",
    "    wake_onset = pd.to_datetime(str(pd.to_datetime(day_row[\"calendar_date\"]).date() + pd.Timedelta(\"1d\")) + \" \" + day_row[\"wakeup_ts\"])\n",
    "\n",
    "    SPT.append((sleep_onset, wake_onset))\n",
    "\n",
    "start_end_sleep = np.array(SPT).reshape(-1, 2)\n",
    "SPT_GGIR = pd.DataFrame(start_end_sleep, columns=[\"start\", \"end\"])\n",
    "SPT_GGIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
