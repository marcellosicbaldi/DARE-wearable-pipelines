{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGE-it - Exploratory Data Analysis\n",
    "\n",
    "- Summary of the recordings - how many hours/days for each sensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1525\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1497\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1476\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib qt\n",
    "\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Slider, Select\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.io import export_png\n",
    "from bokeh.models import DatetimeTickFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to Python's search path\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENEActiv\n",
    "Files are already converted into .bin with the bin2parquet notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08623\n",
      "GeneActivPolso:  7 days 01:20:20\n",
      "GeneActivCaviglia:  7 days 01:19:44\n",
      "\n",
      "08667\n",
      "\n",
      "14219\n",
      "GeneActivPolso:  6 days 22:27:29\n",
      "GeneActivCaviglia:  6 days 22:27:26\n",
      "\n",
      "20603\n",
      "\n",
      "23483\n",
      "GeneActivPolso:  6 days 23:38:14\n",
      "GeneActivCaviglia:  6 days 23:38:20\n",
      "\n",
      "36644\n",
      "GeneActivPolso:  6 days 22:46:32\n",
      "GeneActivCaviglia:  6 days 22:47:14\n",
      "\n",
      "36765\n",
      "\n",
      "36920\n",
      "GeneActivPolso:  5 days 23:55:05\n",
      "GeneActivCaviglia:  5 days 23:54:05\n",
      "\n",
      "58319\n",
      "GeneActivPolso:  0 days 18:23:38\n",
      "GeneActivCaviglia:  7 days 01:19:05\n",
      "\n",
      "59794\n",
      "GeneActivPolso:  6 days 00:47:26\n",
      "GeneActivCaviglia:  6 days 00:32:56\n",
      "\n",
      "65381\n",
      "GeneActivPolso:  7 days 01:47:23\n",
      "GeneActivCaviglia: is empty\n",
      "\n",
      "68503\n",
      "GeneActivPolso:  6 days 01:14:53\n",
      "GeneActivCaviglia:  6 days 01:15:05\n",
      "\n",
      "73496\n",
      "GeneActivPolso:  6 days 22:59:50\n",
      "GeneActivCaviglia:  6 days 22:59:38\n",
      "\n",
      "74003\n",
      "GeneActivPolso: is empty\n",
      "GeneActivCaviglia:  6 days 23:37:05\n",
      "\n",
      "74913\n",
      "GeneActivPolso:  7 days 01:57:35\n",
      "GeneActivCaviglia:  7 days 01:57:35\n",
      "\n",
      "78936\n",
      "GeneActivPolso:  6 days 00:23:11\n",
      "GeneActivCaviglia:  6 days 00:22:47\n",
      "\n",
      "86693\n",
      "GeneActivPolso:  6 days 20:18:17\n",
      "GeneActivCaviglia:  6 days 20:18:26\n",
      "\n",
      "97060\n",
      "GeneActivPolso:  4 days 16:26:56\n",
      "GeneActivCaviglia:  7 days 00:10:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data/\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "\n",
    "# participants = participants[5:6] # select the first participant\n",
    "\n",
    "sensors = [\"GeneActivPolso\", \"GeneActivCaviglia\"]#, \"RootiRx\"]\n",
    "\n",
    "geneactiv = {}\n",
    "\n",
    "for participant in participants:\n",
    "    print(participant)\n",
    "    for sensor in sensors:\n",
    "        # print(sensor)\n",
    "        # Load the data\n",
    "        path = os.path.join(data_path, participant, visit, sensor)\n",
    "        files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "        # if there are already parquet files, skip\n",
    "        for f in files:\n",
    "            if f.endswith(\".parquet\"):\n",
    "                # print(f)\n",
    "                acc_df = pd.read_parquet(os.path.join(path, f))\n",
    "                # geneactiv[sensor] = acc_df\n",
    "                if len(acc_df) == 0:\n",
    "                    print(f\"{sensor}: is empty\")\n",
    "                else:\n",
    "                    print(f\"{sensor}:  {acc_df.index[-1] - acc_df.index[0]}\".split(\".\")[0])\n",
    "\n",
    "    print(\"\")\n",
    "# # Plot the data\n",
    "# p = figure(plot_width=800, plot_height=400, x_axis_type=\"datetime\", title=f\"{participant} - {sensor} - {visit}\")\n",
    "# p.line(data[\"timestamp\"], data[\"x\"], line_width=2, legend_label=\"x\", color=\"blue\")\n",
    "# p.line(data[\"timestamp\"], data[\"y\"], line_width=2, legend_label=\"y\", color=\"green\")\n",
    "# p.line(data[\"timestamp\"], data[\"z\"], line_width=2, legend_label=\"z\", color=\"red\")\n",
    "# p.xaxis.formatter = DatetimeTickFormatter(days=\"%d/%m %H:%M\", hours=\"%H:%M\")\n",
    "# p.legend.location = \"top_left\"\n",
    "# p.legend.click_policy=\"hide\"\n",
    "# show(p)\n",
    "# export_png(p, filename=f\"{participant}_{sensor}_{visit}.png\")\n",
    "# print(f\"{participant}_{sensor}_{visit}.png\")\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneActivPolso: 6 days 22:46:32\n",
      "GeneActivCaviglia: 6 days 22:47:14\n"
     ]
    }
   ],
   "source": [
    "# Recording duration\n",
    "for sensor, data in geneactiv.items():\n",
    "    print(f\"{sensor}: {data.index[-1] - data.index[0]}\".split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x163814170>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geneactiv[\"GeneActivPolso\"][\"acc_SMV\"] = np.sqrt(geneactiv[\"GeneActivPolso\"][\"x\"]**2 + geneactiv[\"GeneActivPolso\"][\"y\"]**2 + geneactiv[\"GeneActivPolso\"][\"z\"]**2)\n",
    "# geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"] = np.sqrt(geneactiv[\"GeneActivCaviglia\"][\"x\"]**2 + geneactiv[\"GeneActivCaviglia\"][\"y\"]**2 + geneactiv[\"GeneActivCaviglia\"][\"z\"]**2)\n",
    "\n",
    "plt.figure(figsize = (19,11))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(geneactiv[\"GeneActivPolso\"][\"acc_SMV\"].iloc[:1000000], label = \"GeneActivPolso\")\n",
    "plt.plot(geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"].iloc[:1000000], label = \"GeneActivCaviglia\")\n",
    "plt.title(\"Recording Start\", fontsize = 21)\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(geneactiv[\"GeneActivPolso\"][\"acc_SMV\"].iloc[-1000000:], label = \"GeneActivPolso\")\n",
    "plt.plot(geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"].iloc[-1000000:], label = \"GeneActivCaviglia\")\n",
    "plt.title(\"Recording End\", fontsize = 21)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verity Sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io.veritysense.convert_polar import process_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastavro\n",
    "\n",
    "def read_avro_veritysense(file_path, offset_vs = 946684800000000000+ 3600 * 1e9):\n",
    "    \"\"\"\n",
    "    Reads an Avro file and returns the data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as avro_file:\n",
    "        # Use fastavro.reader to read the Avro file\n",
    "        reader = fastavro.reader(avro_file)\n",
    "        # Convert the records to a list\n",
    "        records = [record for record in reader]\n",
    "       # to dataframe\n",
    "        df = pd.DataFrame(records)\n",
    "        df.index = pd.to_datetime(df[\"timestamp\"] + offset_vs, unit=\"ns\") \n",
    "        df.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    return df / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to extract full datetime (including time) for sorting\n",
    "def extract_datetime(filename):\n",
    "    match = re.search(r'(\\w{3}) (\\w{3}) (\\d{2}) (\\d{2})-(\\d{2})-(\\d{2}) .* (\\d{4})', filename)\n",
    "    if match:\n",
    "        weekday, month, day, hour, minute, second, year = match.groups()\n",
    "        date_str = f\"{day} {month} {year} {hour}:{minute}:{second}\"\n",
    "        date_obj = datetime.strptime(date_str, \"%d %b %Y %H:%M:%S\")  # Convert to datetime object\n",
    "        return date_obj\n",
    "    return datetime.max  # Default to a max value if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** 23483 ****************\n",
      "\n",
      " ***** Disconnections in ACC *****\n",
      "Number of disconnections: 134\n",
      "Total duration of disconnections: 06:41:26 (hours, minutes and seconds)\n",
      "ACC effective duration: 4 days 16:50:17\n",
      "\n",
      " ***** Disconnections in PPG *****\n",
      "Number of disconnections: 137\n",
      "Total duration of disconnections: 06:11:44 (hours, minutes and seconds)\n",
      "PPG effective duration: 4 days 17:19:59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "\n",
    "# participants = participants[0:1] # select the first participant\n",
    "\n",
    "participants = [\"23483\"]\n",
    "\n",
    "sensor = \"VeritySense\"#, \"GeneActivPolso\", \"GeneActivCaviglia\", \"RootiRx\"]\n",
    "\n",
    "for participant in participants:\n",
    "    acc_df = pd.DataFrame()\n",
    "    ppg_df = pd.DataFrame()\n",
    "    # print(sensor)\n",
    "    path = os.path.join(data_path, participant, visit, sensor)\n",
    "    files_in_path = [f for f in os.listdir(path) if not f.startswith(\".\")]\n",
    "    if len(files_in_path) <= 2: # \"_\" and \"AVRO\"\n",
    "        continue\n",
    "\n",
    "    print(f\"**************** {participant} ****************\")\n",
    "    acc_path = os.path.join(path, \"AVRO/acc\")\n",
    "    ppg_path = os.path.join(path, \"AVRO/ppg\")\n",
    "    for f in sorted(os.listdir(acc_path), key=extract_datetime):\n",
    "        current_acc = read_avro_veritysense(os.path.join(acc_path, f))\n",
    "        acc_df = pd.concat([acc_df, current_acc])\n",
    "\n",
    "    for f in sorted(os.listdir(ppg_path), key=extract_datetime):\n",
    "        current_ppg = read_avro_veritysense(os.path.join(ppg_path, f))\n",
    "        ppg_df = pd.concat([ppg_df, current_ppg])\n",
    "\n",
    "    t_acc_rec = acc_df.index[acc_df.index.to_series().diff().dt.total_seconds() > 0.5]\n",
    "    t_acc_disc = acc_df.index[np.where(acc_df.index.to_series().diff().dt.total_seconds() > 0.5)[0]-1]\n",
    "    t_disc_rec_acc = pd.DataFrame({\"disc\": t_acc_disc, \"rec\": t_acc_rec})\n",
    "    total_duration_acc = acc_df.index[-1] - acc_df.index[0]\n",
    "    disconnetions_duration_acc = t_disc_rec_acc[\"rec\"] - t_disc_rec_acc[\"disc\"]\n",
    "    effective_duration_acc = total_duration_acc - disconnetions_duration_acc.sum()\n",
    "    if len(t_acc_disc) > 0:\n",
    "        print(\"\\n ***** Disconnections in ACC *****\")\n",
    "        # for i in range(len(t_acc_disc)):\n",
    "        #     print(f\"Disconnection {i+1}:\")\n",
    "        #     print(f\"Start: {t_acc_disc[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"End: {t_acc_rec[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"Duration: {str(t_acc_rec[i] - t_acc_disc[i]).split(' ')[2][3:5]} min and {str(t_acc_rec[i] - t_acc_disc[i]).split(' ')[2][6:8]} s\")\n",
    "        print(\"Number of disconnections: \" + str(len(t_acc_disc)))\n",
    "        print(\"Total duration of disconnections: \" + str(np.sum([t_acc_rec[i] - t_acc_disc[i] for i in range(len(t_acc_disc))])).split(' ')[2][:8] + \" (hours, minutes and seconds)\")\n",
    "        print(f\"ACC effective duration: {effective_duration_acc}\".split(\".\")[0])\n",
    "    # Fill disconnection portions with NaNs and linearly interpolate\n",
    "    for start, end in zip(t_acc_disc, t_acc_rec):\n",
    "        acc_df.loc[start:end] = np.nan\n",
    "    acc_df = acc_df.interpolate(method='time')\n",
    "\n",
    "    t_ppg_rec = ppg_df.index[ppg_df.index.to_series().diff().dt.total_seconds() > 1]\n",
    "    t_ppg_disc = ppg_df.index[np.where(ppg_df.index.to_series().diff().dt.total_seconds() > 1)[0]-1]\n",
    "    t_disc_rec_ppg = pd.DataFrame({\"disc\": t_ppg_disc, \"rec\": t_ppg_rec})\n",
    "    total_duration_ppg = ppg_df.index[-1] - ppg_df.index[0]\n",
    "    disconnetions_duration_ppg = t_disc_rec_ppg[\"rec\"] - t_disc_rec_ppg[\"disc\"]\n",
    "    effective_duration_ppg = total_duration_ppg - disconnetions_duration_ppg.sum()\n",
    "    if len(t_ppg_disc) > 0:\n",
    "        print(\"\\n ***** Disconnections in PPG *****\")\n",
    "        # for i in range(len(t_ppg_disc)):\n",
    "        #     print(f\"Disconnection {i+1}:\")\n",
    "        #     print(f\"Start: {t_ppg_disc[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"End: {t_ppg_rec[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"Duration: {str(t_ppg_rec[i] - t_ppg_disc[i]).split(' ')[2][3:5]} min and {str(t_ppg_rec[i] - t_ppg_disc[i]).split(' ')[2][6:8]} s\")\n",
    "        print(\"Number of disconnections: \" + str(len(t_ppg_disc)))\n",
    "        print(\"Total duration of disconnections: \" + str(np.sum([t_ppg_rec[i] - t_ppg_disc[i] for i in range(len(t_ppg_disc))])).split(' ')[2][:8] + \" (hours, minutes and seconds)\")\n",
    "        print(f\"PPG effective duration: {effective_duration_ppg}\".split(\".\")[0])\n",
    "        print(\"\")\n",
    "    # Fill disconnection portions with NaNs and linearly interpolate\n",
    "    for start, end in zip(t_ppg_disc, t_ppg_rec):\n",
    "        ppg_df.loc[start:end] = np.nan\n",
    "    ppg_df = ppg_df.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Soggetto 97060 ------- weird timestamps starting at 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timedelta('6 days 23:31:43.876258560'),\n",
       " Timedelta('2 days 06:41:26.693904128'),\n",
       " Timedelta('4 days 16:50:17.182354432'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dur = acc_df.index[-1] - acc_df.index[0]\n",
    "disconnetions_dur = t_disc_rec_acc[\"rec\"] - t_disc_rec_acc[\"disc\"]\n",
    "effective_dur = total_dur - disconnetions_dur.sum()\n",
    "total_dur, disconnetions_dur.sum(), effective_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-21 16:17:29.975070208 2025-01-21 16:20:03.052938240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppg1</th>\n",
       "      <th>ppg2</th>\n",
       "      <th>ppg3</th>\n",
       "      <th>ambient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ppg1, ppg2, ppg3, ambient]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for start, end in zip(t_acc_disc, t_acc_rec):\n",
    "    print(start,end)\n",
    "    break\n",
    "\n",
    "ppg_df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_df.loc[pd.Timestamp(\"2025-01-21 16:20:03.052938240\"):pd.Timestamp(\"2025-01-22 16:20:03.052938240\")].to_csv(\"ppg_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppg1</th>\n",
       "      <th>ppg2</th>\n",
       "      <th>ppg3</th>\n",
       "      <th>ambient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.344035328</th>\n",
       "      <td>115.751091</td>\n",
       "      <td>19.832478</td>\n",
       "      <td>75.259832</td>\n",
       "      <td>-291.321995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.362216960</th>\n",
       "      <td>115.752000</td>\n",
       "      <td>19.834000</td>\n",
       "      <td>75.260000</td>\n",
       "      <td>-291.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.380399104</th>\n",
       "      <td>115.551000</td>\n",
       "      <td>19.657000</td>\n",
       "      <td>75.209000</td>\n",
       "      <td>-291.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.398580736</th>\n",
       "      <td>115.589000</td>\n",
       "      <td>19.481000</td>\n",
       "      <td>75.181000</td>\n",
       "      <td>-291.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.416762624</th>\n",
       "      <td>115.991000</td>\n",
       "      <td>19.511000</td>\n",
       "      <td>75.189000</td>\n",
       "      <td>-291.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:02.974105088</th>\n",
       "      <td>63.964000</td>\n",
       "      <td>22.219000</td>\n",
       "      <td>25.433000</td>\n",
       "      <td>-291.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:02.992358400</th>\n",
       "      <td>65.248000</td>\n",
       "      <td>23.506000</td>\n",
       "      <td>26.564000</td>\n",
       "      <td>-291.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.010611712</th>\n",
       "      <td>66.445000</td>\n",
       "      <td>24.733000</td>\n",
       "      <td>27.541000</td>\n",
       "      <td>-291.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.028865024</th>\n",
       "      <td>67.564000</td>\n",
       "      <td>25.856000</td>\n",
       "      <td>28.451000</td>\n",
       "      <td>-291.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.047118592</th>\n",
       "      <td>68.555000</td>\n",
       "      <td>26.908000</td>\n",
       "      <td>29.355000</td>\n",
       "      <td>-291.234000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4021486 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ppg1       ppg2       ppg3     ambient\n",
       "timestamp                                                                  \n",
       "2025-01-21 16:20:03.344035328  115.751091  19.832478  75.259832 -291.321995\n",
       "2025-01-21 16:20:03.362216960  115.752000  19.834000  75.260000 -291.322000\n",
       "2025-01-21 16:20:03.380399104  115.551000  19.657000  75.209000 -291.231000\n",
       "2025-01-21 16:20:03.398580736  115.589000  19.481000  75.181000 -291.230000\n",
       "2025-01-21 16:20:03.416762624  115.991000  19.511000  75.189000 -291.263000\n",
       "...                                   ...        ...        ...         ...\n",
       "2025-01-22 16:20:02.974105088   63.964000  22.219000  25.433000 -291.274000\n",
       "2025-01-22 16:20:02.992358400   65.248000  23.506000  26.564000 -291.263000\n",
       "2025-01-22 16:20:03.010611712   66.445000  24.733000  27.541000 -291.279000\n",
       "2025-01-22 16:20:03.028865024   67.564000  25.856000  28.451000 -291.254000\n",
       "2025-01-22 16:20:03.047118592   68.555000  26.908000  29.355000 -291.234000\n",
       "\n",
       "[4021486 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg = pd.read_pickle(\"ppg_df.pkl\")\n",
    "ppg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "ppg_df[\"ppg_filt\"] = -nk.signal_filter(ppg_df[\"ppg1\"], lowcut=0.5, highcut=8, sampling_rate=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PPG')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc_df)\n",
    "plt.title(\"Acceleration\")\n",
    "# plt.legend(acc_df.columns)\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(ppg_df[\"ppg1\"])\n",
    "plt.title(\"PPG\")\n",
    "# plt.legend([\"ppg_filt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall duration of the recording (excluding gaps): 0 days 05:29:49.749643520\n"
     ]
    }
   ],
   "source": [
    "# Calculate the actual recording duration by summing up the differences between consecutive timestamps\n",
    "time_diffs = acc_df.index.to_series().diff().dropna()\n",
    "overall_duration = time_diffs.sum()\n",
    "print(f\"Overall duration of the recording (excluding gaps): {overall_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 05:29:53.340454144')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg_df.index[-1] - ppg_df.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rooti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** 14219 *****\n",
      "Total duration: 6 days 23:49:20\n",
      "\n",
      "***** 36644 *****\n",
      "Total duration: 6 days 22:15:09\n",
      "\n",
      "***** 59794 *****\n",
      "Total duration: 5 days 23:36:26\n",
      "\n",
      "***** 73496 *****\n",
      "Total duration: 2 days 22:04:56\n",
      "\n",
      "***** 74003 *****\n",
      "Total duration: 6 days 16:23:18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data/\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "# participants = [\"14219\"]\n",
    "# participants = participants[5:6] # select the first participant\n",
    "\n",
    "sensors = [\"RootiRx\"]#, \"RootiRx\"]\n",
    "\n",
    "sensor = sensors[0]\n",
    "\n",
    "rootirx = {}\n",
    "\n",
    "for participant in participants:\n",
    "    path = os.path.join(data_path, participant, visit, sensor)\n",
    "    files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "\n",
    "    files = [f for f in files if f == participant]\n",
    "\n",
    "    if len(files) == 0:\n",
    "        # print(\"No RootiRx data\")\n",
    "        continue\n",
    "    \n",
    "    print(\"***** \" + participant + \" *****\")\n",
    "    rooti_path = os.path.join(data_path, participant, visit, sensor, files[0], \"measure\")\n",
    "\n",
    "    raw_acc_path = [x[0] for x in os.walk(rooti_path) if x[0].endswith(\"/GSENSOR\")][0]\n",
    "\n",
    "    # print(raw_acc_path)\n",
    "\n",
    "    acc_files = sorted(os.listdir(raw_acc_path))\n",
    "\n",
    "    # print(len(acc_files))\n",
    "\n",
    "    # acc = pd.DataFrame()\n",
    "\n",
    "    acc_first = pd.read_csv(raw_acc_path + '/' + acc_files[0], compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "    acc_first_start = pd.to_datetime(acc_first.index[0], unit = \"s\")\n",
    "\n",
    "    acc_last = pd.read_csv(raw_acc_path + '/' + acc_files[-1], compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "    acc_last_end = pd.to_datetime(acc_last.index[-1], unit = \"s\")\n",
    "\n",
    "    print(f\"Total duration: {acc_last_end - acc_first_start}\")\n",
    "\n",
    "    # for i, acc_file in enumerate(acc_files):\n",
    "    #     acc1 = pd.read_csv(raw_acc_path + '/' + acc_file, compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "    #     acc1 = acc1[[\"acc_x\", \"acc_y\", \"acc_z\"]]\n",
    "    #     acc1.index = pd.date_range(start = pd.to_datetime(acc1.index[0], unit = \"s\"), periods = len(acc1), freq = \"0.0032s\")\n",
    "    #     acc = pd.concat([acc, acc1])\n",
    "    # break\n",
    "\n",
    "    # print(path)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1737458741.zip',\n",
       " '1737462341.zip',\n",
       " '1737465941.zip',\n",
       " '1737469541.zip',\n",
       " '1737473141.zip',\n",
       " '1737476741.zip',\n",
       " '1737480341.zip',\n",
       " '1737483941.zip',\n",
       " '1737487541.zip',\n",
       " '1737491141.zip',\n",
       " '1737494741.zip',\n",
       " '1737498341.zip',\n",
       " '1737501941.zip',\n",
       " '1737505541.zip',\n",
       " '1737509141.zip',\n",
       " '1737512741.zip',\n",
       " '1737516341.zip',\n",
       " '1737519941.zip',\n",
       " '1737523541.zip',\n",
       " '1737527141.zip',\n",
       " '1737530741.zip',\n",
       " '1737534341.zip',\n",
       " '1737537941.zip',\n",
       " '1737541541.zip',\n",
       " '1737545141.zip',\n",
       " '1737548741.zip',\n",
       " '1737552341.zip',\n",
       " '1737555941.zip',\n",
       " '1737559541.zip',\n",
       " '1737563141.zip',\n",
       " '1737566741.zip',\n",
       " '1737570341.zip',\n",
       " '1737573941.zip',\n",
       " '1737577541.zip',\n",
       " '1737581141.zip',\n",
       " '1737584741.zip',\n",
       " '1737588341.zip',\n",
       " '1737591941.zip',\n",
       " '1737595541.zip',\n",
       " '1737599141.zip',\n",
       " '1737602741.zip',\n",
       " '1737606341.zip',\n",
       " '1737609941.zip',\n",
       " '1737613541.zip',\n",
       " '1737617141.zip',\n",
       " '1737620741.zip',\n",
       " '1737624341.zip',\n",
       " '1737627941.zip',\n",
       " '1737631541.zip',\n",
       " '1737635141.zip',\n",
       " '1737638741.zip',\n",
       " '1737642341.zip',\n",
       " '1737645941.zip',\n",
       " '1737649541.zip',\n",
       " '1737653141.zip',\n",
       " '1737656741.zip',\n",
       " '1737660341.zip',\n",
       " '1737663941.zip',\n",
       " '1737667541.zip',\n",
       " '1737671141.zip',\n",
       " '1737674741.zip',\n",
       " '1737678341.zip',\n",
       " '1737681941.zip',\n",
       " '1737685541.zip',\n",
       " '1737689141.zip',\n",
       " '1737692741.zip',\n",
       " '1737696341.zip',\n",
       " '1737699941.zip',\n",
       " '1737703541.zip',\n",
       " '1737707141.zip',\n",
       " '1737710741.zip',\n",
       " '1737714341.zip',\n",
       " '1737717941.zip',\n",
       " '1737721541.zip',\n",
       " '1737725141.zip',\n",
       " '1737728741.zip',\n",
       " '1737732341.zip',\n",
       " '1737735941.zip',\n",
       " '1737739541.zip',\n",
       " '1737743141.zip',\n",
       " '1737746741.zip',\n",
       " '1737750341.zip',\n",
       " '1737753941.zip',\n",
       " '1737757541.zip',\n",
       " '1737761141.zip',\n",
       " '1737764741.zip',\n",
       " '1737768341.zip',\n",
       " '1737771941.zip',\n",
       " '1737775541.zip',\n",
       " '1737779141.zip',\n",
       " '1737782741.zip',\n",
       " '1737786341.zip',\n",
       " '1737789941.zip',\n",
       " '1737793541.zip',\n",
       " '1737797141.zip',\n",
       " '1737800741.zip',\n",
       " '1737804341.zip',\n",
       " '1737807941.zip',\n",
       " '1737811541.zip',\n",
       " '1737815141.zip',\n",
       " '1737818741.zip',\n",
       " '1737822341.zip',\n",
       " '1737825941.zip',\n",
       " '1737829541.zip',\n",
       " '1737833141.zip',\n",
       " '1737836741.zip',\n",
       " '1737840341.zip',\n",
       " '1737843941.zip',\n",
       " '1737847541.zip',\n",
       " '1737851141.zip',\n",
       " '1737854741.zip',\n",
       " '1737858341.zip',\n",
       " '1737861941.zip',\n",
       " '1737865541.zip',\n",
       " '1737869141.zip',\n",
       " '1737872741.zip',\n",
       " '1737876341.zip',\n",
       " '1737879941.zip',\n",
       " '1737883541.zip',\n",
       " '1737887141.zip',\n",
       " '1737890741.zip',\n",
       " '1737894341.zip',\n",
       " '1737897941.zip',\n",
       " '1737901541.zip',\n",
       " '1737905141.zip',\n",
       " '1737908741.zip',\n",
       " '1737912341.zip',\n",
       " '1737915941.zip',\n",
       " '1737919541.zip',\n",
       " '1737923141.zip',\n",
       " '1737926741.zip',\n",
       " '1737930341.zip',\n",
       " '1737933941.zip',\n",
       " '1737937541.zip',\n",
       " '1737941141.zip',\n",
       " '1737944741.zip',\n",
       " '1737948341.zip',\n",
       " '1737951941.zip',\n",
       " '1737955541.zip',\n",
       " '1737959141.zip',\n",
       " '1737962741.zip',\n",
       " '1737966341.zip',\n",
       " '1737969941.zip',\n",
       " '1737973541.zip',\n",
       " '1737977141.zip',\n",
       " '1737980741.zip',\n",
       " '1737984341.zip',\n",
       " '1737987941.zip',\n",
       " '1737991541.zip',\n",
       " '1737995141.zip',\n",
       " '1737998741.zip',\n",
       " '1738002341.zip',\n",
       " '1738005941.zip',\n",
       " '1738009541.zip',\n",
       " '1738013141.zip',\n",
       " '1738016741.zip',\n",
       " '1738020341.zip',\n",
       " '1738023941.zip',\n",
       " '1738027541.zip',\n",
       " '1738031141.zip',\n",
       " '1738032540.zip']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15f8400e0>,\n",
       " <matplotlib.lines.Line2D at 0x15f842960>,\n",
       " <matplotlib.lines.Line2D at 0x15f842a80>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.plot(acc.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>packet</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>idk</th>\n",
       "      <th>idk2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>-191</td>\n",
       "      <td>1288</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.003200</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>-183</td>\n",
       "      <td>1324</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.006400</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>119</td>\n",
       "      <td>1187</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.009600</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>-164</td>\n",
       "      <td>1379</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.012800</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>-287</td>\n",
       "      <td>1468</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            packet  acc_x  acc_y  acc_z  idk  idk2\n",
       "2025-01-17 10:34:21.000000       0    176   -191   1288   18   166\n",
       "2025-01-17 10:34:21.003200       1    150   -183   1324   18   166\n",
       "2025-01-17 10:34:21.006400       2    150    119   1187   18   166\n",
       "2025-01-17 10:34:21.009600       3    115   -164   1379   18   166\n",
       "2025-01-17 10:34:21.012800       4     60   -287   1468   18   166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
