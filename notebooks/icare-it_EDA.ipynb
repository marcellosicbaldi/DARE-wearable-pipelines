{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGE-it - Exploratory Data Analysis\n",
    "\n",
    "- Summary of the recordings - how many hours/days for each sensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib qt\n",
    "\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Slider, Select\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.io import export_png\n",
    "from bokeh.models import DatetimeTickFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENEActiv\n",
    "Files are already converted into .bin with the bin2parquet notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08623\n",
      "GeneActivPolso:  7 days 01:20:20\n",
      "GeneActivCaviglia:  7 days 01:19:44\n",
      "\n",
      "08667\n",
      "\n",
      "14219\n",
      "GeneActivPolso:  6 days 22:27:29\n",
      "GeneActivCaviglia:  6 days 22:27:26\n",
      "\n",
      "20603\n",
      "\n",
      "23483\n",
      "GeneActivPolso:  6 days 23:38:14\n",
      "GeneActivCaviglia:  6 days 23:38:20\n",
      "\n",
      "36644\n",
      "GeneActivPolso:  6 days 22:46:32\n",
      "GeneActivCaviglia:  6 days 22:47:14\n",
      "\n",
      "36765\n",
      "\n",
      "36920\n",
      "GeneActivPolso:  5 days 23:55:05\n",
      "GeneActivCaviglia:  5 days 23:54:05\n",
      "\n",
      "58319\n",
      "GeneActivPolso:  0 days 18:23:38\n",
      "GeneActivCaviglia:  7 days 01:19:05\n",
      "\n",
      "59794\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data/\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "\n",
    "# participants = participants[5:6] # select the first participant\n",
    "\n",
    "sensors = [\"GeneActivPolso\", \"GeneActivCaviglia\"]#, \"RootiRx\"]\n",
    "\n",
    "geneactiv = {}\n",
    "\n",
    "for participant in participants:\n",
    "    print(participant)\n",
    "    for sensor in sensors:\n",
    "        # print(sensor)\n",
    "        # Load the data\n",
    "        path = os.path.join(data_path, participant, visit, sensor)\n",
    "        files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "        # if there are already parquet files, skip\n",
    "        for f in files:\n",
    "            if f.endswith(\".parquet\"):\n",
    "                # print(f)\n",
    "                acc_df = pd.read_parquet(os.path.join(path, f))\n",
    "                # geneactiv[sensor] = acc_df\n",
    "                if len(acc_df) == 0:\n",
    "                    print(f\"{sensor}: is empty\")\n",
    "                else:\n",
    "                    print(f\"{sensor}:  {acc_df.index[-1] - acc_df.index[0]}\".split(\".\")[0])\n",
    "\n",
    "    print(\"\")\n",
    "# # Plot the data\n",
    "# p = figure(plot_width=800, plot_height=400, x_axis_type=\"datetime\", title=f\"{participant} - {sensor} - {visit}\")\n",
    "# p.line(data[\"timestamp\"], data[\"x\"], line_width=2, legend_label=\"x\", color=\"blue\")\n",
    "# p.line(data[\"timestamp\"], data[\"y\"], line_width=2, legend_label=\"y\", color=\"green\")\n",
    "# p.line(data[\"timestamp\"], data[\"z\"], line_width=2, legend_label=\"z\", color=\"red\")\n",
    "# p.xaxis.formatter = DatetimeTickFormatter(days=\"%d/%m %H:%M\", hours=\"%H:%M\")\n",
    "# p.legend.location = \"top_left\"\n",
    "# p.legend.click_policy=\"hide\"\n",
    "# show(p)\n",
    "# export_png(p, filename=f\"{participant}_{sensor}_{visit}.png\")\n",
    "# print(f\"{participant}_{sensor}_{visit}.png\")\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneActivPolso: 6 days 22:46:32\n",
      "GeneActivCaviglia: 6 days 22:47:14\n"
     ]
    }
   ],
   "source": [
    "# Recording duration\n",
    "for sensor, data in geneactiv.items():\n",
    "    print(f\"{sensor}: {data.index[-1] - data.index[0]}\".split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x163814170>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# geneactiv[\"GeneActivPolso\"][\"acc_SMV\"] = np.sqrt(geneactiv[\"GeneActivPolso\"][\"x\"]**2 + geneactiv[\"GeneActivPolso\"][\"y\"]**2 + geneactiv[\"GeneActivPolso\"][\"z\"]**2)\n",
    "# geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"] = np.sqrt(geneactiv[\"GeneActivCaviglia\"][\"x\"]**2 + geneactiv[\"GeneActivCaviglia\"][\"y\"]**2 + geneactiv[\"GeneActivCaviglia\"][\"z\"]**2)\n",
    "\n",
    "plt.figure(figsize = (19,11))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(geneactiv[\"GeneActivPolso\"][\"acc_SMV\"].iloc[:1000000], label = \"GeneActivPolso\")\n",
    "plt.plot(geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"].iloc[:1000000], label = \"GeneActivCaviglia\")\n",
    "plt.title(\"Recording Start\", fontsize = 21)\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(geneactiv[\"GeneActivPolso\"][\"acc_SMV\"].iloc[-1000000:], label = \"GeneActivPolso\")\n",
    "plt.plot(geneactiv[\"GeneActivCaviglia\"][\"acc_SMV\"].iloc[-1000000:], label = \"GeneActivCaviglia\")\n",
    "plt.title(\"Recording End\", fontsize = 21)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verity Sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_io.veritysense.convert_polar import process_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastavro\n",
    "\n",
    "def read_avro_veritysense(file_path, offset_vs = 946684800000000000+ 3600 * 1e9):\n",
    "    \"\"\"\n",
    "    Reads an Avro file and returns the data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as avro_file:\n",
    "        # Use fastavro.reader to read the Avro file\n",
    "        reader = fastavro.reader(avro_file)\n",
    "        # Convert the records to a list\n",
    "        records = [record for record in reader]\n",
    "       # to dataframe\n",
    "        df = pd.DataFrame(records)\n",
    "        df.index = pd.to_datetime(df[\"timestamp\"] + offset_vs, unit=\"ns\") \n",
    "        df.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    return df / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to extract full datetime (including time) for sorting\n",
    "def extract_datetime(filename):\n",
    "    match = re.search(r'(\\w{3}) (\\w{3}) (\\d{2}) (\\d{2})-(\\d{2})-(\\d{2}) .* (\\d{4})', filename)\n",
    "    if match:\n",
    "        weekday, month, day, hour, minute, second, year = match.groups()\n",
    "        date_str = f\"{day} {month} {year} {hour}:{minute}:{second}\"\n",
    "        date_obj = datetime.strptime(date_str, \"%d %b %Y %H:%M:%S\")  # Convert to datetime object\n",
    "        return date_obj\n",
    "    return datetime.max  # Default to a max value if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** 23483 ****************\n",
      "\n",
      " ***** Disconnections in ACC *****\n",
      "Number of disconnections: 134\n",
      "Total duration of disconnections: 06:41:26 (hours, minutes and seconds)\n",
      "ACC effective duration: 4 days 16:50:17\n",
      "\n",
      " ***** Disconnections in PPG *****\n",
      "Number of disconnections: 137\n",
      "Total duration of disconnections: 06:11:44 (hours, minutes and seconds)\n",
      "PPG effective duration: 4 days 17:19:59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "\n",
    "# participants = participants[0:1] # select the first participant\n",
    "\n",
    "participants = [\"23483\"]\n",
    "\n",
    "sensor = \"VeritySense\"#, \"GeneActivPolso\", \"GeneActivCaviglia\", \"RootiRx\"]\n",
    "\n",
    "for participant in participants:\n",
    "    acc_df = pd.DataFrame()\n",
    "    ppg_df = pd.DataFrame()\n",
    "    # print(sensor)\n",
    "    path = os.path.join(data_path, participant, visit, sensor)\n",
    "    files_in_path = [f for f in os.listdir(path) if not f.startswith(\".\")]\n",
    "    if len(files_in_path) <= 2: # \"_\" and \"AVRO\"\n",
    "        continue\n",
    "\n",
    "    print(f\"**************** {participant} ****************\")\n",
    "    acc_path = os.path.join(path, \"AVRO/acc\")\n",
    "    ppg_path = os.path.join(path, \"AVRO/ppg\")\n",
    "    for f in sorted(os.listdir(acc_path), key=extract_datetime):\n",
    "        current_acc = read_avro_veritysense(os.path.join(acc_path, f))\n",
    "        acc_df = pd.concat([acc_df, current_acc])\n",
    "\n",
    "    for f in sorted(os.listdir(ppg_path), key=extract_datetime):\n",
    "        current_ppg = read_avro_veritysense(os.path.join(ppg_path, f))\n",
    "        ppg_df = pd.concat([ppg_df, current_ppg])\n",
    "\n",
    "    t_acc_rec = acc_df.index[acc_df.index.to_series().diff().dt.total_seconds() > 0.5]\n",
    "    t_acc_disc = acc_df.index[np.where(acc_df.index.to_series().diff().dt.total_seconds() > 0.5)[0]-1]\n",
    "    t_disc_rec_acc = pd.DataFrame({\"disc\": t_acc_disc, \"rec\": t_acc_rec})\n",
    "    total_duration_acc = acc_df.index[-1] - acc_df.index[0]\n",
    "    disconnetions_duration_acc = t_disc_rec_acc[\"rec\"] - t_disc_rec_acc[\"disc\"]\n",
    "    effective_duration_acc = total_duration_acc - disconnetions_duration_acc.sum()\n",
    "    if len(t_acc_disc) > 0:\n",
    "        print(\"\\n ***** Disconnections in ACC *****\")\n",
    "        # for i in range(len(t_acc_disc)):\n",
    "        #     print(f\"Disconnection {i+1}:\")\n",
    "        #     print(f\"Start: {t_acc_disc[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"End: {t_acc_rec[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"Duration: {str(t_acc_rec[i] - t_acc_disc[i]).split(' ')[2][3:5]} min and {str(t_acc_rec[i] - t_acc_disc[i]).split(' ')[2][6:8]} s\")\n",
    "        print(\"Number of disconnections: \" + str(len(t_acc_disc)))\n",
    "        print(\"Total duration of disconnections: \" + str(np.sum([t_acc_rec[i] - t_acc_disc[i] for i in range(len(t_acc_disc))])).split(' ')[2][:8] + \" (hours, minutes and seconds)\")\n",
    "        print(f\"ACC effective duration: {effective_duration_acc}\".split(\".\")[0])\n",
    "    # Fill disconnection portions with NaNs and linearly interpolate\n",
    "    for start, end in zip(t_acc_disc, t_acc_rec):\n",
    "        acc_df.loc[start:end] = np.nan\n",
    "    acc_df = acc_df.interpolate(method='time')\n",
    "\n",
    "    t_ppg_rec = ppg_df.index[ppg_df.index.to_series().diff().dt.total_seconds() > 1]\n",
    "    t_ppg_disc = ppg_df.index[np.where(ppg_df.index.to_series().diff().dt.total_seconds() > 1)[0]-1]\n",
    "    t_disc_rec_ppg = pd.DataFrame({\"disc\": t_ppg_disc, \"rec\": t_ppg_rec})\n",
    "    total_duration_ppg = ppg_df.index[-1] - ppg_df.index[0]\n",
    "    disconnetions_duration_ppg = t_disc_rec_ppg[\"rec\"] - t_disc_rec_ppg[\"disc\"]\n",
    "    effective_duration_ppg = total_duration_ppg - disconnetions_duration_ppg.sum()\n",
    "    if len(t_ppg_disc) > 0:\n",
    "        print(\"\\n ***** Disconnections in PPG *****\")\n",
    "        # for i in range(len(t_ppg_disc)):\n",
    "        #     print(f\"Disconnection {i+1}:\")\n",
    "        #     print(f\"Start: {t_ppg_disc[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"End: {t_ppg_rec[i].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        #     print(f\"Duration: {str(t_ppg_rec[i] - t_ppg_disc[i]).split(' ')[2][3:5]} min and {str(t_ppg_rec[i] - t_ppg_disc[i]).split(' ')[2][6:8]} s\")\n",
    "        print(\"Number of disconnections: \" + str(len(t_ppg_disc)))\n",
    "        print(\"Total duration of disconnections: \" + str(np.sum([t_ppg_rec[i] - t_ppg_disc[i] for i in range(len(t_ppg_disc))])).split(' ')[2][:8] + \" (hours, minutes and seconds)\")\n",
    "        print(f\"PPG effective duration: {effective_duration_ppg}\".split(\".\")[0])\n",
    "        print(\"\")\n",
    "    # Fill disconnection portions with NaNs and linearly interpolate\n",
    "    for start, end in zip(t_ppg_disc, t_ppg_rec):\n",
    "        ppg_df.loc[start:end] = np.nan\n",
    "    ppg_df = ppg_df.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Soggetto 97060 ------- weird timestamps starting at 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timedelta('6 days 23:31:43.876258560'),\n",
       " Timedelta('2 days 06:41:26.693904128'),\n",
       " Timedelta('4 days 16:50:17.182354432'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_dur = acc_df.index[-1] - acc_df.index[0]\n",
    "disconnetions_dur = t_disc_rec_acc[\"rec\"] - t_disc_rec_acc[\"disc\"]\n",
    "effective_dur = total_dur - disconnetions_dur.sum()\n",
    "total_dur, disconnetions_dur.sum(), effective_dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-21 16:17:29.975070208 2025-01-21 16:20:03.052938240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppg1</th>\n",
       "      <th>ppg2</th>\n",
       "      <th>ppg3</th>\n",
       "      <th>ambient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ppg1, ppg2, ppg3, ambient]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for start, end in zip(t_acc_disc, t_acc_rec):\n",
    "    print(start,end)\n",
    "    break\n",
    "\n",
    "ppg_df.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_df.loc[pd.Timestamp(\"2025-01-21 16:20:03.052938240\"):pd.Timestamp(\"2025-01-22 16:20:03.052938240\")].to_csv(\"ppg_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppg1</th>\n",
       "      <th>ppg2</th>\n",
       "      <th>ppg3</th>\n",
       "      <th>ambient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.344035328</th>\n",
       "      <td>115.751091</td>\n",
       "      <td>19.832478</td>\n",
       "      <td>75.259832</td>\n",
       "      <td>-291.321995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.362216960</th>\n",
       "      <td>115.752000</td>\n",
       "      <td>19.834000</td>\n",
       "      <td>75.260000</td>\n",
       "      <td>-291.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.380399104</th>\n",
       "      <td>115.551000</td>\n",
       "      <td>19.657000</td>\n",
       "      <td>75.209000</td>\n",
       "      <td>-291.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.398580736</th>\n",
       "      <td>115.589000</td>\n",
       "      <td>19.481000</td>\n",
       "      <td>75.181000</td>\n",
       "      <td>-291.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-21 16:20:03.416762624</th>\n",
       "      <td>115.991000</td>\n",
       "      <td>19.511000</td>\n",
       "      <td>75.189000</td>\n",
       "      <td>-291.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:02.974105088</th>\n",
       "      <td>63.964000</td>\n",
       "      <td>22.219000</td>\n",
       "      <td>25.433000</td>\n",
       "      <td>-291.274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:02.992358400</th>\n",
       "      <td>65.248000</td>\n",
       "      <td>23.506000</td>\n",
       "      <td>26.564000</td>\n",
       "      <td>-291.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.010611712</th>\n",
       "      <td>66.445000</td>\n",
       "      <td>24.733000</td>\n",
       "      <td>27.541000</td>\n",
       "      <td>-291.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.028865024</th>\n",
       "      <td>67.564000</td>\n",
       "      <td>25.856000</td>\n",
       "      <td>28.451000</td>\n",
       "      <td>-291.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22 16:20:03.047118592</th>\n",
       "      <td>68.555000</td>\n",
       "      <td>26.908000</td>\n",
       "      <td>29.355000</td>\n",
       "      <td>-291.234000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4021486 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ppg1       ppg2       ppg3     ambient\n",
       "timestamp                                                                  \n",
       "2025-01-21 16:20:03.344035328  115.751091  19.832478  75.259832 -291.321995\n",
       "2025-01-21 16:20:03.362216960  115.752000  19.834000  75.260000 -291.322000\n",
       "2025-01-21 16:20:03.380399104  115.551000  19.657000  75.209000 -291.231000\n",
       "2025-01-21 16:20:03.398580736  115.589000  19.481000  75.181000 -291.230000\n",
       "2025-01-21 16:20:03.416762624  115.991000  19.511000  75.189000 -291.263000\n",
       "...                                   ...        ...        ...         ...\n",
       "2025-01-22 16:20:02.974105088   63.964000  22.219000  25.433000 -291.274000\n",
       "2025-01-22 16:20:02.992358400   65.248000  23.506000  26.564000 -291.263000\n",
       "2025-01-22 16:20:03.010611712   66.445000  24.733000  27.541000 -291.279000\n",
       "2025-01-22 16:20:03.028865024   67.564000  25.856000  28.451000 -291.254000\n",
       "2025-01-22 16:20:03.047118592   68.555000  26.908000  29.355000 -291.234000\n",
       "\n",
       "[4021486 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppg = pd.read_pickle(\"ppg_df.pkl\")\n",
    "ppg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurokit2 as nk\n",
    "ppg_df[\"ppg_filt\"] = -nk.signal_filter(ppg_df[\"ppg1\"], lowcut=0.5, highcut=8, sampling_rate=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PPG')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc_df)\n",
    "plt.title(\"Acceleration\")\n",
    "# plt.legend(acc_df.columns)\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(ppg_df[\"ppg1\"])\n",
    "plt.title(\"PPG\")\n",
    "# plt.legend([\"ppg_filt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall duration of the recording (excluding gaps): 0 days 05:29:49.749643520\n"
     ]
    }
   ],
   "source": [
    "# Calculate the actual recording duration by summing up the differences between consecutive timestamps\n",
    "time_diffs = acc_df.index.to_series().diff().dropna()\n",
    "overall_duration = time_diffs.sum()\n",
    "print(f\"Overall duration of the recording (excluding gaps): {overall_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 05:29:53.340454144')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppg_df.index[-1] - ppg_df.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rooti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** 14219 *****\n",
      "Total duration: 6 days 23:49:20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data/\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "participants = [\"14219\"]\n",
    "# participants = participants[5:6] # select the first participant\n",
    "\n",
    "sensors = [\"RootiRx\"]#, \"RootiRx\"]\n",
    "\n",
    "sensor = sensors[0]\n",
    "\n",
    "rootirx = {}\n",
    "\n",
    "for participant in participants:\n",
    "    path = os.path.join(data_path, participant, visit, sensor)\n",
    "    files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "\n",
    "    files = [f for f in files if f == participant]\n",
    "\n",
    "    if len(files) == 0:\n",
    "        # print(\"No RootiRx data\")\n",
    "        continue\n",
    "    \n",
    "    print(\"***** \" + participant + \" *****\")\n",
    "    rooti_path = os.path.join(data_path, participant, visit, sensor, files[0], \"measure\")\n",
    "\n",
    "    raw_acc_path = [x[0] for x in os.walk(rooti_path) if x[0].endswith(\"/GSENSOR\")][0]\n",
    "\n",
    "    # print(raw_acc_path)\n",
    "\n",
    "    acc_files = sorted(os.listdir(raw_acc_path))\n",
    "\n",
    "    # print(len(acc_files))\n",
    "\n",
    "    acc = pd.DataFrame()\n",
    "\n",
    "    acc_first = pd.read_csv(raw_acc_path + '/' + acc_files[0], compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "    acc_first_start = pd.to_datetime(acc_first.index[0], unit = \"s\")\n",
    "\n",
    "    acc_last = pd.read_csv(raw_acc_path + '/' + acc_files[-1], compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "    acc_last_end = pd.to_datetime(acc_last.index[-1], unit = \"s\")\n",
    "\n",
    "    print(f\"Total duration: {acc_last_end - acc_first_start}\")\n",
    "\n",
    "    for i, acc_file in enumerate(acc_files):\n",
    "        acc1 = pd.read_csv(raw_acc_path + '/' + acc_file, compression='zip', index_col = 0, header = None, names = [\"packet\", \"acc_x\", \"acc_y\", \"acc_z\", \"idk\", \"idk2\"])\n",
    "        acc1 = acc1[[\"acc_x\", \"acc_y\", \"acc_z\"]]\n",
    "        acc1.index = pd.date_range(start = pd.to_datetime(acc1.index[0], unit = \"s\"), periods = len(acc1), freq = \"0.032s\")\n",
    "        acc = pd.concat([acc, acc1])\n",
    "\n",
    "    # print(path)\n",
    "\n",
    "    print(\"\")\n",
    "    break\n",
    "\n",
    "    # print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1585d9730>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.plot(np.diff(acc.index).astype('timedelta64[s]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>packet</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>idk</th>\n",
       "      <th>idk2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>-191</td>\n",
       "      <td>1288</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.003200</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>-183</td>\n",
       "      <td>1324</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.006400</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>119</td>\n",
       "      <td>1187</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.009600</th>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>-164</td>\n",
       "      <td>1379</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.012800</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>-287</td>\n",
       "      <td>1468</td>\n",
       "      <td>18</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            packet  acc_x  acc_y  acc_z  idk  idk2\n",
       "2025-01-17 10:34:21.000000       0    176   -191   1288   18   166\n",
       "2025-01-17 10:34:21.003200       1    150   -183   1324   18   166\n",
       "2025-01-17 10:34:21.006400       2    150    119   1187   18   166\n",
       "2025-01-17 10:34:21.009600       3    115   -164   1379   18   166\n",
       "2025-01-17 10:34:21.012800       4     60   -287   1468   18   166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synch between GENEActiv and Rooti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14219\n",
      "GeneActivPolso:  6 days 22:27:29\n",
      "GeneActivCaviglia:  6 days 22:27:26\n",
      "\n",
      "***** 14219 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8x/dvs9gy2x1fq3xdz6r9lt_t_40000gp/T/ipykernel_42501/1118766901.py:64: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  t_acc_rooti = pd.concat([t_acc_rooti, t_acc1.to_series()])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/augenpro/Documents/Age-IT/data/\" # path to the folder containing the subjects\n",
    "participants = sorted([p for p in os.listdir(data_path) if not p.startswith(\".\")]) # list of the participants\n",
    "visit = \"T0 (baseline)\" # T0 (baseline), T1 (follow-up @ 6 months), T2 (follow-up @ 12 months)\n",
    "\n",
    "# participants = participants[5:6] # select the first participant\n",
    "\n",
    "sensors = [\"GeneActivPolso\", \"GeneActivCaviglia\"]#, \"RootiRx\"]\n",
    "\n",
    "geneactiv = {}\n",
    "\n",
    "participants = [\"14219\"]\n",
    "\n",
    "for participant in participants:\n",
    "    print(participant)\n",
    "    for sensor in sensors:\n",
    "        path = os.path.join(data_path, participant, visit, sensor)\n",
    "        files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "        # if there are already parquet files, skip\n",
    "        for f in files:\n",
    "            if f.endswith(\".parquet\"):\n",
    "                # print(f)\n",
    "                acc_gen = pd.read_parquet(os.path.join(path, f))\n",
    "                # geneactiv[sensor] = acc_gen\n",
    "                if len(acc_gen) == 0:\n",
    "                    print(f\"{sensor}: is empty\")\n",
    "                else:\n",
    "                    print(f\"{sensor}:  {acc_gen.index[-1] - acc_gen.index[0]}\".split(\".\")[0])\n",
    "                if sensor == \"GeneActivPolso\":\n",
    "                    geneactiv[\"wrist\"] = acc_gen\n",
    "                elif sensor == \"GeneActivCaviglia\":\n",
    "                    geneactiv[\"ankle\"] = acc_gen\n",
    "                del acc_gen\n",
    "    print(\"\")\n",
    "\n",
    "# Rooti\n",
    "sensor = \"RootiRx\"\n",
    "for participant in participants:\n",
    "    path = os.path.join(data_path, participant, visit, sensor)\n",
    "    files = os.listdir(os.path.join(data_path, participant, visit, sensor))\n",
    "\n",
    "    files = [f for f in files if f == participant]\n",
    "\n",
    "    if len(files) == 0:\n",
    "        # print(\"No RootiRx data\")\n",
    "        continue\n",
    "    \n",
    "    print(\"***** \" + participant + \" *****\")\n",
    "    rooti_path = os.path.join(data_path, participant, visit, sensor, files[0], \"measure\")\n",
    "\n",
    "    raw_acc_path = [x[0] for x in os.walk(rooti_path) if x[0].endswith(\"/GSENSOR\")][0]\n",
    "    acc_files = sorted(os.listdir(raw_acc_path))\n",
    "    acc_rooti = pd.DataFrame()\n",
    "    t_acc_rooti = pd.Series()\n",
    "    first_acc_file = pd.read_csv(raw_acc_path + '/' + acc_files[0], compression='zip', index_col = 0, header = None)\n",
    "    t_start_rooti = pd.to_datetime(first_acc_file.index[0], unit = \"s\")\n",
    "    for i, acc_file in enumerate(acc_files):\n",
    "        acc1 = pd.read_csv(raw_acc_path + '/' + acc_files[i], compression='zip', index_col = 0, header = None) / 1000 # convert to g\n",
    "        t_acc_start = pd.to_datetime(acc1.index[0], unit = \"s\")\n",
    "        t_acc_end = pd.to_datetime(acc1.index[-1]+1, unit = \"s\")\n",
    "        acc1 = acc1.iloc[:, [1, 2, 3]].reset_index(drop = True)\n",
    "        acc1.columns = [\"acc_x\", \"acc_y\", \"acc_z\"]\n",
    "        t_acc1 = pd.date_range(start = t_acc_start, end = t_acc_end, periods=len(acc1)+1)[:-1]\n",
    "        acc_rooti = pd.concat([acc_rooti, acc1])\n",
    "        t_acc_rooti = pd.concat([t_acc_rooti, t_acc1.to_series()])\n",
    "\n",
    "    ecg_filtered_path = [x[0] for x in os.walk(rooti_path) if x[0].endswith(\"/FilteredECG\")][0] + \"/250\"\n",
    "    ecg_filtered_files = sorted(os.listdir(ecg_filtered_path))\n",
    "    ecg_dataframes = []\n",
    "\n",
    "    # Iterate through ecg filtered files\n",
    "    for i, ecg_file in enumerate(ecg_filtered_files):\n",
    "        ecg_filtered_df = pd.read_csv(\n",
    "            ecg_filtered_path + '/' + ecg_file, \n",
    "            compression='zip', \n",
    "            header=None, \n",
    "            names=[\"ecg\", \"Rpeaks\"]\n",
    "        )\n",
    "        # t_start = pd.to_datetime(ecg_filtered_files[0].split(\".\")[0], unit = \"s\")\n",
    "        # ecg_filtered_df.index = pd.date_range(start = t_start, periods = len(ecg_filtered_df), freq = \"0.004s\")\n",
    "        ecg_dataframes.append(ecg_filtered_df)\n",
    "    t_start_ecg = pd.to_datetime(int(ecg_filtered_files[0].split(\".\")[0]), unit = \"s\")\n",
    "    ecg_filtered = pd.concat(ecg_dataframes, axis=0)\n",
    "    ecg_filtered.index = pd.date_range(start = t_start_ecg, periods = len(ecg_filtered), freq = \"0.004s\")\n",
    "\n",
    "    # print(path)\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_filtered.to_parquet(ecg_filtered_path + \"/ecg_filtered.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(t_acc_rooti.diff().dropna().dt.total_seconds())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ecg_filtered.index.diff().dropna().total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ecg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Rpeaks",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bd304db7-224a-4db2-82d2-4783ffe222dd",
       "rows": [
        [
         "2025-01-17 10:34:21",
         "16.445",
         null
        ],
        [
         "2025-01-17 10:34:21.004000",
         "5.801",
         null
        ],
        [
         "2025-01-17 10:34:21.008000",
         "-1.034",
         null
        ],
        [
         "2025-01-17 10:34:21.012000",
         "-2.867",
         null
        ],
        [
         "2025-01-17 10:34:21.016000",
         "-1.026",
         null
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecg</th>\n",
       "      <th>Rpeaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.000</th>\n",
       "      <td>16.445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.004</th>\n",
       "      <td>5.801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.008</th>\n",
       "      <td>-1.034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.012</th>\n",
       "      <td>-2.867</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 10:34:21.016</th>\n",
       "      <td>-1.026</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ecg Rpeaks\n",
       "2025-01-17 10:34:21.000  16.445    NaN\n",
       "2025-01-17 10:34:21.004   5.801    NaN\n",
       "2025-01-17 10:34:21.008  -1.034    NaN\n",
       "2025-01-17 10:34:21.012  -2.867    NaN\n",
       "2025-01-17 10:34:21.016  -1.026    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2025-01-24 10:14:21'), Timestamp('2025-01-17 10:34:21'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_filtered[\"ecg\"].index[0], t_acc_rooti.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x138a5ba70>,\n",
       " <matplotlib.lines.Line2D at 0x12df75bb0>,\n",
       " <matplotlib.lines.Line2D at 0x14cb63290>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(ecg_filtered[\"ecg\"].loc[pd.Timestamp(\"2025-01-17 11:34:21\"):pd.Timestamp(\"2025-01-18 11:34:21\") + pd.Timedelta(hours = 1)])\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(acc_rooti.loc[pd.Timestamp(\"2025-01-17 11:34:21\"):pd.Timestamp(\"2025-01-18 11:34:21\") + pd.Timedelta(hours = 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rooti.index = t_acc_rooti.index #+ pd.Timedelta(\"1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compute_acc_SMV import compute_acc_SMV\n",
    "\n",
    "acc_rooti[\"acc_SMV\"] = compute_acc_SMV(acc_rooti)\n",
    "acc_gen[\"acc_SMV\"] = compute_acc_SMV(acc_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13e3a8b00>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (19,11))\n",
    "plt.plot(acc_gen[\"acc_SMV\"].iloc[:500000], label = \"GENEActiv\", linewidth = 0.91)\n",
    "plt.plot(acc_rooti[\"acc_SMV\"].iloc[:500000], label = \"RootiRx\", linewidth = 0.91)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script that check for cross-correlations between different sensors, and adjust the start time accordingly\n",
    "\n",
    "Assumption: the rotations are done within the first hour of recording\n",
    "\n",
    "1. Resample the first hour of the signals to the same number of samples (for geneactiv 100 Hz)\n",
    "2. Segment signal in 20 second windows with an overlap of 10s (the rotations last 10 seconds)\n",
    "3. Compute the CCF for each of the windows \n",
    "4. Find the maximum and plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Resample the overall Rooti signal to the same number of samples (for geneactiv 100 Hz)\n",
    "\n",
    "from utils.resample_signal import apply_resample\n",
    "\n",
    "fs_res = 100\n",
    "\n",
    "t_acc_rooti_resampled, acc_rooti_resampled = apply_resample(time = acc_rooti.index.astype(np.int64).to_numpy(), time_rs = acc_gen.index.astype(np.int64).to_numpy(), \n",
    "                                     data = acc_rooti[\"acc_SMV\"].values)\n",
    "\n",
    "acc_rooti_resampled = pd.Series(acc_rooti_resampled[0], index = pd.to_datetime(t_acc_rooti_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Resample the first hour of the signals to the same number of samples (for geneactiv 100 Hz)\n",
    "\n",
    "from utils.resample_signal import apply_resample\n",
    "\n",
    "fs_res = 100\n",
    "\n",
    "acc_rooti_first_hour = acc_rooti.loc[:t_start_rooti + pd.Timedelta(\"2h\")][\"acc_SMV\"]\n",
    "acc_gen_first_hour = acc_gen.loc[:acc_gen.index[0] + pd.Timedelta(\"1h\")][\"acc_SMV\"]\n",
    "\n",
    "t_acc_rooti_resampled, acc_rooti_resampled = apply_resample(time = acc_rooti_first_hour.index.astype(np.int64).to_numpy(), time_rs = acc_gen_first_hour.index.astype(np.int64).to_numpy(), \n",
    "                                     data = acc_rooti_first_hour.values)\n",
    "\n",
    "acc_rooti_resampled = pd.Series(acc_rooti_resampled[0], index = pd.to_datetime(t_acc_rooti_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Segment the signals into 20s windows with 50% overlap\n",
    "\n",
    "from utils.segment_signal import segment_signal\n",
    "\n",
    "acc_gen_segments = segment_signal(acc_gen_first_hour, window_size = 20*fs_res, overlap = 0.5)\n",
    "# acc_rooti_segments = segment_signal(acc_rooti_resampled, window_size = 20*fs_res, overlap = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compute the crosscorrelation between the two signals for each window\n",
    "from utils.crosscorr import crosscorr\n",
    "\n",
    "offsets = []\n",
    "max_corr = []\n",
    "lags = np.arange(-400, 401, 1) # 400 samples = 4s, resolution of 1 samples = 0.01s\n",
    "for i, (gen, rooti) in enumerate(zip(acc_gen_segments, acc_rooti_segments)):\n",
    "    if len(gen) != len(rooti):\n",
    "        continue\n",
    "    ccf = [crosscorr(gen, rooti, lag) for lag in lags]\n",
    "    max_corr.append(np.max(ccf))\n",
    "    offset = np.argmax(ccf) - lags[-1]\n",
    "    offset_s = offset / fs_res\n",
    "    offsets.append(offset_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13daacaa0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize = (11,5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(max_corr, '-*', label = \"Max correlation\")\n",
    "plt.xlabel(\"Window\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(offsets, '-*', label = \"Offset (s)\")\n",
    "plt.xlabel(\"Window\")\n",
    "plt.ylabel(\"Offset (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13dc872f0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum correlation and the corresponding offset\n",
    "max_corr = np.array(max_corr)\n",
    "offsets = np.array(offsets)\n",
    "max_corr_idx = np.argmax(max_corr)\n",
    "max_corr_val = max_corr[max_corr_idx]\n",
    "\n",
    "# Apply the offset to the RootiRx signal\n",
    "offset = offsets[max_corr_idx]\n",
    "\n",
    "acc_rooti_synched = acc_rooti.copy()\n",
    "acc_rooti_synched.index = acc_rooti_synched.index - pd.Timedelta(f\"{offset}s\")\n",
    "# Plot the signals\n",
    "plt.figure(figsize = (19,11))\n",
    "plt.plot(acc_gen[\"acc_SMV\"].iloc[:500000], label = \"GENEActiv ACC SMV\")\n",
    "plt.plot(acc_rooti_synched[\"acc_SMV\"].iloc[:500000], label = \"RootiRx ACC SMV\")\n",
    "plt.ylabel(\"Acceleration (g)\")\n",
    "plt.legend(loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it for all GENEActiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['wrist', 'ankle'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geneactiv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compute_acc_SMV import compute_acc_SMV\n",
    "\n",
    "# Compute SMV for the GENEActiv signals\n",
    "geneactiv[\"wrist\"][\"acc_SMV\"] = compute_acc_SMV(geneactiv[\"wrist\"])\n",
    "geneactiv[\"ankle\"][\"acc_SMV\"] = compute_acc_SMV(geneactiv[\"ankle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_gen_wirst_first_hour = geneactiv[\"wrist\"].loc[:geneactiv[\"wrist\"].index[0] + pd.Timedelta(\"5min\")][\"acc_SMV\"]\n",
    "acc_gen_ankle_first_hour = geneactiv[\"ankle\"].loc[:geneactiv[\"ankle\"].index[0] + pd.Timedelta(\"5min\")][\"acc_SMV\"]\n",
    "\n",
    "# 1. Resample the first hour of the signals to the same number of samples (for geneactiv 100 Hz)\n",
    "fs_res = 100\n",
    "\n",
    "from utils.resample_signal import apply_resample\n",
    "\n",
    "t_acc_gen_ankle_resampled, acc_gen_ankle_resampled = apply_resample(time = acc_gen_ankle_first_hour.index.astype(np.int64).to_numpy(), time_rs = acc_gen_wirst_first_hour.index.astype(np.int64).to_numpy(), \n",
    "                                     data = acc_gen_ankle_first_hour.values)\n",
    "\n",
    "acc_gen_ankle_resampled = pd.Series(acc_gen_ankle_resampled[0], index = pd.to_datetime(t_acc_gen_ankle_resampled))\n",
    "\n",
    "# 2. Segment the signals into 20s windows with 50% overlap\n",
    "\n",
    "from utils.segment_signal import segment_signal\n",
    "\n",
    "acc_gen_wrist_segments = segment_signal(acc_gen_wirst_first_hour, window_size = 20*fs_res, overlap = 0.5)\n",
    "acc_gen_ankle_segments = segment_signal(acc_gen_ankle_resampled, window_size = 20*fs_res, overlap = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025-01-17 11:38:44.000000000    0.987872\n",
       "2025-01-17 11:38:44.009999990    1.025177\n",
       "2025-01-17 11:38:44.019999981    1.045466\n",
       "2025-01-17 11:38:44.029999971    1.076971\n",
       "2025-01-17 11:38:44.039999962    1.043428\n",
       "                                   ...   \n",
       "2025-01-17 11:43:43.960000038    1.005571\n",
       "2025-01-17 11:43:43.970000029    1.005720\n",
       "2025-01-17 11:43:43.980000019    1.012752\n",
       "2025-01-17 11:43:43.990000010    1.011449\n",
       "2025-01-17 11:43:44.000000000    1.015252\n",
       "Name: acc_SMV, Length: 30001, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_gen_wirst_first_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x3c7dac740>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Compute the crosscorrelation between the two signals for each window\n",
    "\n",
    "from utils.crosscorr import crosscorr\n",
    "\n",
    "offsets = []\n",
    "max_corr = []\n",
    "lags = np.arange(-400, 401, 1) # 400 samples = 4s, resolution of 1 samples = 0.01s\n",
    "for i, (wrist, ankle) in enumerate(zip(acc_gen_wrist_segments, acc_gen_ankle_segments)):\n",
    "    if len(wrist) != len(ankle):\n",
    "        continue\n",
    "    ccf = [crosscorr(wrist, ankle, lag) for lag in lags]\n",
    "    max_corr.append(np.max(ccf))\n",
    "    offset = np.argmax(ccf) - lags[-1]\n",
    "    offset_s = offset / fs_res\n",
    "    offsets.append(offset_s)\n",
    "\n",
    "plt.figure(figsize = (11,5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(max_corr, '-*', label = \"Max correlation\")\n",
    "plt.xlabel(\"Window\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(offsets, '-*', label = \"Offset (s)\")\n",
    "plt.xlabel(\"Window\")\n",
    "plt.ylabel(\"Offset (s)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x38d5156a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum correlation and the corresponding offset\n",
    "max_corr = np.array(max_corr)\n",
    "offsets = np.array(offsets)\n",
    "max_corr_idx = np.argmax(max_corr)\n",
    "max_corr_val = max_corr[max_corr_idx]\n",
    "offset = offsets[max_corr_idx]\n",
    "\n",
    "# Apply the offset to the GENEActiv ankle signal\n",
    "acc_gen_ankle_synched = geneactiv[\"ankle\"].copy()\n",
    "acc_gen_ankle_synched.index = acc_gen_ankle_synched.index - pd.Timedelta(f\"{offset}s\")\n",
    "\n",
    "# Plot the signals\n",
    "plt.figure(figsize = (19,11))\n",
    "plt.plot(geneactiv[\"wrist\"][\"acc_SMV\"].iloc[:500000], label = \"GENEActiv wrist ACC SMV\")\n",
    "plt.plot(acc_gen_ankle_synched[\"acc_SMV\"].iloc[:500000], label = \"GENEActiv ankle ACC SMV\")\n",
    "plt.ylabel(\"Acceleration (g)\")\n",
    "plt.legend(loc = \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "z",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "acc_SMV",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "738393fb-115d-4750-a357-7becef71638b",
       "rows": [
        [
         "2025-01-17 11:38:44",
         "-0.14322027166573995",
         "-0.9759112771793139",
         "0.05455548115177059",
         "0.9878720401273989"
        ],
        [
         "2025-01-17 11:38:44.009999990",
         "-0.13130510763364842",
         "-1.0156616448702152",
         "0.046677433332020325",
         "1.0251772485446702"
        ],
        [
         "2025-01-17 11:38:44.019999981",
         "-0.13130510763364842",
         "-1.0355368287156657",
         "0.058494505061645725",
         "1.0454660023356037"
        ],
        [
         "2025-01-17 11:38:44.029999971",
         "-0.12733338628961793",
         "-1.0633620860992965",
         "0.11364083979989759",
         "1.076971196405853"
        ],
        [
         "2025-01-17 11:38:44.039999962",
         "-0.11938994360155691",
         "-1.0315617919465756",
         "0.10182376807027219",
         "1.0434278935227108"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>acc_SMV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-01-17 11:38:44.000000000</th>\n",
       "      <td>-0.143220</td>\n",
       "      <td>-0.975911</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.987872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 11:38:44.009999990</th>\n",
       "      <td>-0.131305</td>\n",
       "      <td>-1.015662</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>1.025177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 11:38:44.019999981</th>\n",
       "      <td>-0.131305</td>\n",
       "      <td>-1.035537</td>\n",
       "      <td>0.058495</td>\n",
       "      <td>1.045466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 11:38:44.029999971</th>\n",
       "      <td>-0.127333</td>\n",
       "      <td>-1.063362</td>\n",
       "      <td>0.113641</td>\n",
       "      <td>1.076971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-17 11:38:44.039999962</th>\n",
       "      <td>-0.119390</td>\n",
       "      <td>-1.031562</td>\n",
       "      <td>0.101824</td>\n",
       "      <td>1.043428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      x         y         z   acc_SMV\n",
       "2025-01-17 11:38:44.000000000 -0.143220 -0.975911  0.054555  0.987872\n",
       "2025-01-17 11:38:44.009999990 -0.131305 -1.015662  0.046677  1.025177\n",
       "2025-01-17 11:38:44.019999981 -0.131305 -1.035537  0.058495  1.045466\n",
       "2025-01-17 11:38:44.029999971 -0.127333 -1.063362  0.113641  1.076971\n",
       "2025-01-17 11:38:44.039999962 -0.119390 -1.031562  0.101824  1.043428"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geneactiv[\"wrist\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonwear.DETACH import nimbaldetach\n",
    "\n",
    "# Apply the non-wear detection algorithm to the GENEActiv wrist signal\n",
    "start_stop_nw, _ = nimbaldetach(acc['x'].values, acc['y'].values, acc['z'].values, temp[\"temp\"].values, accel_freq=64, temperature_freq=1, quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
