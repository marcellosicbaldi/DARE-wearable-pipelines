{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib qt\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Slider, Select\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Range1d\n",
    "from bokeh.io import export_png\n",
    "from bokeh.models import DatetimeTickFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "processed_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input/\"\n",
    "\n",
    "start_end_sleep = np.load(processed_data_path + \"SPT_window_GGIR.npy\", allow_pickle=True)\n",
    "ppg_df = pd.read_parquet(processed_data_path + \"ppg.parquet\")\n",
    "temp_df = pd.read_parquet(processed_data_path + \"temp.parquet\")\n",
    "acc_df = pd.read_parquet(processed_data_path + \"acc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to divide it into portions when the device was \n",
    "\n",
    "t_empty_end = acc_df.index[acc_df.index.to_series().diff().dt.total_seconds() > 1]\n",
    "t_empty_start = acc_df.index[np.where(acc_df.index.to_series().diff().dt.total_seconds() > 1)[0]-1]\n",
    "t_empty = pd.DataFrame({\"start\": t_empty_start, \"end\": t_empty_end})\n",
    "\n",
    "good_portions = pd.DataFrame(columns=[\"start\", \"end\"])\n",
    "good_portions[\"start\"] = t_empty[\"end\"].iloc[:-1].reset_index(drop=True)\n",
    "good_portions[\"end\"] = t_empty[\"start\"].iloc[1:].reset_index(drop=True)\n",
    "start_first_empty = t_empty[\"start\"].iloc[0]\n",
    "end_last_empty = t_empty[\"end\"].iloc[-1]\n",
    "\n",
    "# Segment the data into portions when the device was not in empty and perform nonwear detection\n",
    "acc_df_portions = [acc_df[:start_first_empty]]\n",
    "ppg_df_portions = [ppg_df[:start_first_empty]]\n",
    "\n",
    "for i, row in good_portions.iterrows():\n",
    "\n",
    "    if row[\"end\"] - row[\"start\"] < pd.Timedelta(\"10 min\"): # if the portion is less than 10 minutes, skip it\n",
    "        continue\n",
    "\n",
    "    acc_df_portions.append(acc_df[row[\"start\"]:row[\"end\"]])\n",
    "    ppg_df_portions.append(ppg_df[row[\"start\"]:row[\"end\"]])\n",
    "\n",
    "acc_df_portions.append(acc_df[end_last_empty:])\n",
    "ppg_df_portions.append(ppg_df[end_last_empty:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'beliefppg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mheart_rate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeliefppg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_hr\n",
      "File \u001b[0;32m~/Documents/DARE-wearable-pipelines/notebooks/../heart_rate/beliefppg/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m;os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_USE_LEGACY_KERAS\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_hr, infer_hr_uncertainty\n",
      "File \u001b[0;32m~/Documents/DARE-wearable-pipelines/notebooks/../heart_rate/beliefppg/inference/inference.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbeliefppg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     prepare_session_spec,\n\u001b[1;32m     12\u001b[0m     prepare_session_time,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbeliefppg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputConfig\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbeliefppg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_inference_model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'beliefppg'"
     ]
    }
   ],
   "source": [
    "from heart_rate.beliefppg.inference.inference import infer_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (acc_df_portion, ppg_df_portion) in enumerate(zip(acc_df_portions, ppg_df_portions)):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(ppg_df_portion.resample(\"0.1s\").mean(), label=f\"portion {i}\")\n",
    "    plt.plot(acc_df_portion[\"x\"].resample(\"0.1s\").mean(), label=f\"portion {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 59s 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 11:49:30.038977: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 8s 74ms/step\n",
      "368/368 [==============================] - 28s 75ms/step\n",
      "171/171 [==============================] - 14s 77ms/step\n",
      "30/30 [==============================] - 3s 71ms/step\n",
      "234/234 [==============================] - 18s 76ms/step\n",
      "267/267 [==============================] - 21s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "hr_all = []\n",
    "time_hr_all = []\n",
    "for acc, ppg in zip(acc_df_portions, ppg_df_portions): ##### Each portion has the same shape between ACC and PPG lesgooo\n",
    "   time = acc.index # same as ppg.index\n",
    "   hr, idxs = infer_hr(ppg=ppg.values.reshape(-1,1), ppg_freq=64, acc=acc.values, acc_freq=64)\n",
    "   hr_all.append(hr)\n",
    "   time_hr_all.append(time[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233108,), (233108,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_belief = np.concatenate(hr_all)\n",
    "t_hr_belief = np.concatenate(time_hr_all)\n",
    "\n",
    "hr_belief.shape, t_hr_belief.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x178c05f40>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_belief_df = pd.Series(hr_belief, index=t_hr_belief)\n",
    "plt.figure()\n",
    "plt.plot(hr_belief_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_belief_df.to_pickle(parquet_path + \"hr_belief.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
