{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on mean HR (every 2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "\n",
    "processed_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input/\"\n",
    "\n",
    "start_end_sleep = np.load(processed_data_path + \"SPT_window_GGIR.npy\", allow_pickle=True)\n",
    "ppg_df = pd.read_parquet(processed_data_path + \"ppg.parquet\")\n",
    "temp_df = pd.read_parquet(processed_data_path + \"temp.parquet\")\n",
    "acc_df = pd.read_parquet(processed_data_path + \"acc.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to divide it into portions when the device was \n",
    "\n",
    "t_empty_end = acc_df.index[acc_df.index.to_series().diff().dt.total_seconds() > 1]\n",
    "t_empty_start = acc_df.index[np.where(acc_df.index.to_series().diff().dt.total_seconds() > 1)[0]-1]\n",
    "t_empty = pd.DataFrame({\"start\": t_empty_start, \"end\": t_empty_end})\n",
    "\n",
    "good_portions = pd.DataFrame(columns=[\"start\", \"end\"])\n",
    "good_portions[\"start\"] = t_empty[\"end\"].iloc[:-1].reset_index(drop=True)\n",
    "good_portions[\"end\"] = t_empty[\"start\"].iloc[1:].reset_index(drop=True)\n",
    "start_first_empty = t_empty[\"start\"].iloc[0]\n",
    "end_last_empty = t_empty[\"end\"].iloc[-1]\n",
    "\n",
    "# Segment the data into portions when the device was not in empty and perform nonwear detection\n",
    "acc_df_portions = [acc_df[:start_first_empty]]\n",
    "ppg_df_portions = [ppg_df[:start_first_empty]]\n",
    "\n",
    "for i, row in good_portions.iterrows():\n",
    "\n",
    "    if row[\"end\"] - row[\"start\"] < pd.Timedelta(\"10 min\"): # if the portion is less than 10 minutes, skip it\n",
    "        continue\n",
    "\n",
    "    acc_df_portions.append(acc_df[row[\"start\"]:row[\"end\"]])\n",
    "    ppg_df_portions.append(ppg_df[row[\"start\"]:row[\"end\"]])\n",
    "\n",
    "acc_df_portions.append(acc_df[end_last_empty:])\n",
    "ppg_df_portions.append(ppg_df[end_last_empty:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heart_rate.beliefppg.inference.inference import infer_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 59s 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 11:49:30.038977: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 8s 74ms/step\n",
      "368/368 [==============================] - 28s 75ms/step\n",
      "171/171 [==============================] - 14s 77ms/step\n",
      "30/30 [==============================] - 3s 71ms/step\n",
      "234/234 [==============================] - 18s 76ms/step\n",
      "267/267 [==============================] - 21s 75ms/step\n"
     ]
    }
   ],
   "source": [
    "hr_all = []\n",
    "time_hr_all = []\n",
    "for acc, ppg in zip(acc_df_portions, ppg_df_portions): ##### Each portion has the same shape between ACC and PPG lesgooo\n",
    "   time = acc.index # same as ppg.index\n",
    "   hr, idxs = infer_hr(ppg=ppg.values.reshape(-1,1), ppg_freq=64, acc=acc.values, acc_freq=64)\n",
    "   hr_all.append(hr)\n",
    "   time_hr_all.append(time[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233108,), (233108,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the portions\n",
    "hr_belief = np.concatenate(hr_all)\n",
    "t_hr_belief = np.concatenate(time_hr_all)\n",
    "\n",
    "# Convert to pandas Series\n",
    "hr_belief_df = pd.Series(hr_belief, index=t_hr_belief)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "save_data_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/heart_rate/\"\n",
    "hr_belief_df.to_csv(save_data_path + \"hr_belief.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 11:59:04,573 Starting Bokeh server version 3.6.2 (running on Tornado 6.4.2)\n",
      "2025-02-15 11:59:04,575 User authentication hooks NOT provided (default user enabled)\n",
      "2025-02-15 11:59:04,577 Bokeh app running at: http://localhost:5006/plot_hr\n",
      "2025-02-15 11:59:04,577 Starting Bokeh server with process id: 2553\n",
      "2025-02-15 11:59:05,612 WebSocket connection opened\n",
      "2025-02-15 11:59:05,612 ServerConnection created\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "hr_file_path = \"/Users/augenpro/Documents/Empatica/data_sara/data/GGIR_input/\"\n",
    "hr_file = os.path.join(hr_file_path, \"hr_belief.pkl\")\n",
    "spt_file = os.path.join(hr_file_path, \"SPT_window_GGIR.npy\")\n",
    "\n",
    "# This calls the script to plot the HR\n",
    "script_path = os.path.abspath(\"../visualization/plot_hr.py\")\n",
    "bokeh_process = subprocess.Popen([\n",
    "    \"bokeh\", \"serve\", \"--show\", script_path,\n",
    "    \"--args\", \"--hr_file\", hr_file, \"--spt_file\", spt_file\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To kill the bokeh process: \n",
    " - open terminal\n",
    " - write kill -9 <process_id>, where process_id is the process ID of the bokeh server, that can be found in the cell above (Starting Bokeh server with process id: 2553)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
